{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "source": [
    "def load_xls_to_pandas(filepath , sheet_name):\n",
    "    xls = pd.ExcelFile(filepath)\n",
    "    df = pd.read_excel(xls, sheet_name)\n",
    "    df.columns = df.iloc[1]\n",
    "    # remove row 1 and 2\n",
    "    df = df.iloc[2:]\n",
    "    return df\n",
    "\n",
    "df_raw = load_xls_to_pandas('data/hp_retro_data.xls', 'Discretized Data (Final)')\n",
    "print(df_raw.shape)\n",
    "df_raw.head(10)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "source": [
    "# num_cols = [\"TEMP\", \"HEART_RATE\", \"AGE\", \"DURATION\", \"WBC\", \"ESR\"]\n",
    "# cat_cols = [\"SEX\", \"PREV_VISIT\", \"HX_TRAUMA\", \"COMPLAINT_SITE\", \"HX_ILLNESS\",\n",
    "#             \"GAIT_REPORTED\", \"APPEARANCE\", \"HIP_REST\", \"HIP_ROM\", \"HIP_INT_ROT\",\n",
    "#             \"HIP_INT_ROT\", \"HIP_FLEXION\", \"GAIT_OBSERVED\", \"PAIN_ROM_HIP\", \"OTHER_PAIN_SITE\",\n",
    "#             \"PAIN_PALPATION\", \"SWELLING\", \"CURRENT_ILLNESS\", \"PREV_PROBLEMS\"]\n",
    "\n",
    "cat_bins = {\n",
    "        \"TRIAGE\": {\"DISCHARGE\": 0, \"XRAY\": 0, \"LAB_XRAY_BSCAN\": 1},\n",
    "        \"OTHER_PAIN_SITE\": {np.nan: 0, 'NO': 1, 'OTHER': 2,\n",
    "                            'PELVIS': 3,'BACK': 4, 'LEG': 5},\n",
    "        }\n",
    "\n",
    "def preproc_df(df):\n",
    "    df = df.replace('?', np.nan)\n",
    "    print(df.isnull().sum())\n",
    "\n",
    "    # df = df.dropna(axis=1, thresh=200)\n",
    "    \n",
    "    # create maps for all variables\n",
    "    for col in set(df.columns) - set([\"NUMBER\", \"TRIAGE\"]):\n",
    "        if col not in cat_bins:\n",
    "            if np.nan in list(df[col].unique()):\n",
    "                vals = [np.nan] + list(set(df[col].unique()) - {np.nan})\n",
    "            else:\n",
    "                vals = list(set(df[col].unique()))\n",
    "            cat_bins[col] = {k: v for v, k in enumerate(vals)}\n",
    "\n",
    "    # map categorical variables using cat_bins\n",
    "    for col in df.columns:\n",
    "        if col in cat_bins:\n",
    "            df[col] = df[col].map(cat_bins[col])\n",
    "\n",
    "    # encode categorical variables\n",
    "    # print number of different variables in categorical columns\n",
    "\n",
    "    # encode nans as a new category\n",
    "    return df\n",
    "\n",
    "df = preproc_df(df_raw.copy(deep=True))\n",
    "df.head(10)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "source": [
    "# count unique in TRIAGE\n",
    "triage_counts = df['TRIAGE'].value_counts()\n",
    "print(triage_counts)\n",
    "\n",
    "# plot\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(style=\"whitegrid\")\n",
    "ax = sns.barplot(triage_counts, alpha=0.8)\n",
    "ax.set_ylabel('Number of examples')\n",
    "ax.set_xlabel('Encoded triage class')\n",
    "plt.title('Triage class distribution')\n",
    "plt.show()\n",
    "\n",
    "print(\"Percent of classes:\")\n",
    "print(triage_counts[0] / triage_counts.sum())\n",
    "print(triage_counts[1] / triage_counts.sum())"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "source": [
    "df.describe()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "source": [
    "print(df.shape)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split, supersample, encode (one-hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import KFold, RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "X = df.drop(columns=['NUMBER', 'TRIAGE'])\n",
    "y = df['TRIAGE']\n",
    "\n",
    "print('Original dataset shape %s' % Counter(y))\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "source": [
    "def show_correlations(df: pd.DataFrame) -> None:\n",
    "    plt.figure(figsize=(24, 10))\n",
    "    correlation_matrix = df.corr(method=\"kendall\")\n",
    "    sns.heatmap(correlation_matrix, annot=True, cmap=\"Blues\")\n",
    "\n",
    "\n",
    "show_correlations(pd.concat([X, y], axis=1))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "source": [
    "# split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "print('Train and test datasets shape %s' % Counter(y_train), Counter(y_test))\n",
    "\n",
    "sm = SMOTE(random_state=42)\n",
    "\n",
    "encoder = OneHotEncoder()\n",
    "X, y = encoder.fit_transform(X.values), y.values\n",
    "\n",
    "k_folds = 5\n",
    "kf = RepeatedStratifiedKFold(n_splits=k_folds, n_repeats=5, random_state=42)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "source": [
    "X.shape"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "source": [
    "from sklearn.metrics import confusion_matrix, roc_auc_score, roc_curve, precision_recall_curve, auc\n",
    "\n",
    "def calculate_risk_thresholds(y: np.ndarray, y_pred: np.ndarray) -> tuple[float, float]:\n",
    "    fpr, tpr, thresholds = roc_curve(y, y_pred)\n",
    "    sensitivity, specificity = tpr, 1 - fpr\n",
    "\n",
    "    medium_risk = (\n",
    "        thresholds[np.where(sensitivity >= 0.99)[0][0]] if np.any(sensitivity >= 0.99) else None\n",
    "    )\n",
    "    high_risk = (\n",
    "        thresholds[np.where(specificity >= 0.90)[0][-1]] if np.any(specificity >= 0.90) else None\n",
    "    )\n",
    "    return medium_risk, high_risk\n",
    "\n",
    "def make_prediction(y_pred_proba: np.ndarray, medium_risk: float, high_risk: float) -> np.ndarray:\n",
    "    return np.array(\n",
    "        [\n",
    "            False if response < medium_risk else True if response >= high_risk else np.nan\n",
    "            for response in y_pred_proba\n",
    "        ]\n",
    "    )\n",
    "\n",
    "def calculate_rates(y: np.ndarray, y_pred: np.ndarray) -> tuple[float, float, float, float]:\n",
    "    tn, fp, fn, tp = confusion_matrix(y, y_pred).ravel()\n",
    "    # positives, negatives = tp + fn, tn + fp\n",
    "\n",
    "    tpr = tp / (tp + fn)  # sensitivity\n",
    "    fnr = fn / (fn + tp)  # miss_rate\n",
    "    fpr = fp / (fp + tn)  # fall_out\n",
    "    tnr = tn / (tn + fp)  # specificity\n",
    "\n",
    "    return tpr, fnr, fpr, tnr\n",
    "\n",
    "def auprc_score(y: np.ndarray, y_pred: np.ndarray) -> float:\n",
    "    precision, recall, _ = precision_recall_curve(y, y_pred)\n",
    "    return auc(recall, precision)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "source": [
    "def assess_classifier(X, y, classifier):\n",
    "    \n",
    "    auprc, auroc = [], []\n",
    "    negatives, positives, unknowns = [], [], []\n",
    "    rates = []\n",
    "    \n",
    "    for train, test in kf.split(X, y):\n",
    "\n",
    "        X_train, X_test = X[train], X[test]\n",
    "        y_train, y_test = y[train], y[test]\n",
    "\n",
    "        y_pred_proba_train = classifier.predict_proba(X_train)[:, 1]\n",
    "        medium_risk, high_risk = calculate_risk_thresholds(y_train, y_pred_proba_train)\n",
    "        \n",
    "        y_pred_proba = classifier.predict_proba(X_test)[:, 1]\n",
    "        auprc.append(auprc_score(y_test, y_pred_proba))\n",
    "        auroc.append(roc_auc_score(y_test, y_pred_proba))\n",
    "\n",
    "        predicted = make_prediction(y_pred_proba, medium_risk, high_risk)\n",
    "\n",
    "        positive = np.sum(predicted == True)\n",
    "        negative = np.sum(predicted == False)\n",
    "        unknown = np.sum(np.isnan(predicted))\n",
    "\n",
    "        number_of_samples: int = X_test.shape[0]\n",
    "        negatives.append(negative / number_of_samples)\n",
    "        positives.append(positive / number_of_samples)\n",
    "        unknowns.append(unknown / number_of_samples)\n",
    "\n",
    "        mask = ~np.isnan(predicted)\n",
    "        rates.append(calculate_rates(y_test[mask], predicted[mask]))\n",
    "\n",
    "    return {\n",
    "        \"auprc\": np.mean(auprc),\n",
    "        \"auroc\": np.mean(auroc),\n",
    "        \"negatives\": np.mean(negatives),\n",
    "        \"positives\": np.mean(positives),\n",
    "        \"unknowns\": np.mean(unknowns),\n",
    "        \"rates\": np.mean(rates, axis=0),\n",
    "        }"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### baseline model - logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "source": [
    "from sklearn.linear_model import LogisticRegression \n",
    "\n",
    "# Create a RandomForestClassifier instance\n",
    "\n",
    "classifier = LogisticRegression(random_state=42, max_iter=1000)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "baseline_model = classifier\n",
    "baseline_assessment = assess_classifier(X, y, baseline_model)\n",
    "baseline_assessment\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "source": [
    "from sklearn.ensemble import RandomForestClassifier \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a RandomForestClassifier instance\n",
    "\n",
    "rf_models = []\n",
    "baseline_models_assessments = []\n",
    "for train, test in kf.split(X, y):    \n",
    "    X_train, X_test = X[train], X[test]\n",
    "    y_train, y_test = y[train], y[test]\n",
    "\n",
    "    classifier = RandomForestClassifier(random_state=42)\n",
    "\n",
    "    X_train_res, y_train_res = sm.fit_resample(X_train, y_train)\n",
    "    classifier.fit(X_train_res, y_train_res)\n",
    "\n",
    "    rf_models.append({\n",
    "        'model': classifier,\n",
    "        'assesment': assess_classifier(X, y, classifier)\n",
    "            })\n",
    "\n",
    "best_model = max(rf_models, key=lambda x: x['assesment']['auroc'])\n",
    "\n",
    "best_model['assesment']"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "source": [
    "kfold_results = {\n",
    "    'base': baseline_assessment,\n",
    "    'best': best_model['assesment']\n",
    "}"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "source": [
    "def show_result(result: dict, classifier: str) -> None:\n",
    "    two_colors, three_colors, four_colors = [\n",
    "        sns.color_palette(\"magma\", number) for number in (2, 3, 4)\n",
    "    ]\n",
    "    fig, axs = plt.subplots(2, 2, figsize=(12, 8), tight_layout=True)\n",
    "    ax1, ax2, ax3, ax4 = axs.flatten()\n",
    "\n",
    "    ax1.bar(\n",
    "        [\"AUPRC\", \"AUROC\"],\n",
    "        [result[\"auprc\"], result[\"auroc\"]],\n",
    "        color=two_colors,\n",
    "    )\n",
    "    ax1.grid(axis=\"y\", linestyle=\"--\", alpha=0.25)\n",
    "    for i, value in enumerate([result[\"auprc\"], result[\"auroc\"]]):\n",
    "        ax1.text(i, value, f\"{value * 100:.2f}%\", ha=\"center\", va=\"bottom\")\n",
    "    ax1.set_xlabel(\"metric\")\n",
    "    ax1.set_ylabel(\"score\")\n",
    "    ax1.set_title(\"Scores\")\n",
    "\n",
    "    ax2.bar(\n",
    "        [\"Negatives\", \"Positives\", \"Unknowns\"],\n",
    "        [result[\"negatives\"], result[\"positives\"], result[\"unknowns\"]],\n",
    "        color=three_colors,\n",
    "    )\n",
    "    ax2.grid(axis=\"y\", linestyle=\"--\", alpha=0.25)\n",
    "    for i, value in enumerate([result[\"negatives\"], result[\"positives\"], result[\"unknowns\"]]):\n",
    "        ax2.text(i, value, f\"{value * 100:.2f}%\", ha=\"center\", va=\"bottom\")\n",
    "    ax2.set_xlabel(\"class\")\n",
    "    ax2.set_ylabel(\"percentage\")\n",
    "    ax2.set_title(\"Classification Distribution\")\n",
    "\n",
    "    ax3.bar([\"TPR\", \"FNR\", \"FPR\", \"TNR\"], result[\"rates\"], color=four_colors)\n",
    "    ax3.grid(axis=\"y\", linestyle=\"--\", alpha=0.25)\n",
    "    for i, value in enumerate(result[\"rates\"]):\n",
    "        ax3.text(i, value, f\"{value * 100:.2f}%\", ha=\"center\", va=\"bottom\")\n",
    "    ax3.set_xlabel(\"type\")\n",
    "    ax3.set_ylabel(\"rate\")\n",
    "    ax3.set_title(\"Classification Rates\")\n",
    "\n",
    "    # sns.heatmap(result[\"confusion_matrix\"], annot=True, cmap=\"Blues\", ax=ax4)\n",
    "    # ax4.set_xticklabels([\"Predicted 0\", \"Predicted 1\"])\n",
    "    # ax4.set_yticklabels([\"Actual 0\", \"Actual 1\"])\n",
    "    # ax4.set_title(\"Confusion Matrix (mean)\")\n",
    "    ax4.axis(\"off\")\n",
    "\n",
    "    fig.suptitle(f\"Results for {classifier.capitalize()}\")\n",
    "    fig.savefig(f\"./resources/figures/hp_retro/{classifier}.png\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "for classifier, result in kfold_results.items():\n",
    "    show_result(result, classifier)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "source": [
    "import pickle\n",
    "\n",
    "pickle.dump(baseline_model, open('baseline_model.p', 'wb'))\n",
    "\n",
    "pickle.dump(best_model['model'], open('best_model.p', 'wb'))"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
