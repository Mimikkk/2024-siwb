{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projekt 4: Generalna ocena jakości modeli przestrzennych RNA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO\n",
    "- [x] add parsing and concatenation to all nucleotides (lines in pbd file)  of a data point\n",
    "- [x] concatenate both feature formats (pbd and tor) to one vector\n",
    "- [ ] apply padding in nn input to max no of nucleotides (lines in pbd files)\n",
    "- [ ] apply holdout to nn training (instead of x,y)\n",
    "- [ ] normalize data\n",
    "- [ ] change how nan values are treated\n",
    "- [ ] \"stratify\" holdout sets to fairly distribute all 10 models\n",
    "- [ ] implement model training pipeline to follow training loop\n",
    "- [ ] test out models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# %pip install pandas biopython joblib scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from Bio.PDB import PDBParser\n",
    "from joblib import Parallel, delayed\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Zapoznanie się z udostępnionymi zbiorami danych i ewentualne przetransformowanie ich do postaci ułatwiającej zastosowanie technik sztucznej inteligencji np. integracja danych składowych przechowywanych w różnych formatach z wykorzystaniem jednej spójnej reprezentacji."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "DATASET_PATH = Path(\"./resources/datasets/RNA-Puzzles\")\n",
    "\n",
    "challenges = [f\"pz{index:02}\" for index in range(1, 11)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>number_of_segments</th>\n",
       "      <th>number_of_residues</th>\n",
       "      <th>nucleotide_ranges</th>\n",
       "      <th>sequences</th>\n",
       "      <th>challenge_number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1_solution_0_rpr_A_4_C</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>A1-A8, B10-B16, B19-B23</td>\n",
       "      <td>CCGCCGCG, CAUGCCU, GGCGG</td>\n",
       "      <td>pz01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1_solution_0_rpr_A_5_C</td>\n",
       "      <td>3</td>\n",
       "      <td>23</td>\n",
       "      <td>A1-A9, B8-B15, B18-B23</td>\n",
       "      <td>CCGCCGCGC, GCCAUGCC, UGGCGG</td>\n",
       "      <td>pz01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1_solution_0_rpr_A_6_G</td>\n",
       "      <td>3</td>\n",
       "      <td>24</td>\n",
       "      <td>A2-A10, B7-B14, B17-B23</td>\n",
       "      <td>CGCCGCGCC, CGCCAUGC, GUGGCGG</td>\n",
       "      <td>pz01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1_solution_0_rpr_A_7_C</td>\n",
       "      <td>3</td>\n",
       "      <td>24</td>\n",
       "      <td>A3-A11, B6-B13, B16-B22</td>\n",
       "      <td>GCCGCGCCA, GCGCCAUG, UGUGGCG</td>\n",
       "      <td>pz01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1_solution_0_rpr_A_8_G</td>\n",
       "      <td>3</td>\n",
       "      <td>24</td>\n",
       "      <td>A4-A12, B5-B12, B15-B21</td>\n",
       "      <td>CCGCGCCAU, CGCGCCAU, CUGUGGC</td>\n",
       "      <td>pz01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>673</th>\n",
       "      <td>10_0_solution_4LCK_rpr_B_55_C</td>\n",
       "      <td>3</td>\n",
       "      <td>32</td>\n",
       "      <td>A48-A63, B16-B21, B50-B59</td>\n",
       "      <td>AGGAUAGUGAAAGCUA, UGGUAG, GGGUUCGAAU</td>\n",
       "      <td>pz10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>674</th>\n",
       "      <td>10_0_solution_4LCK_rpr_B_56_G</td>\n",
       "      <td>3</td>\n",
       "      <td>38</td>\n",
       "      <td>A48-A64, B15-B22, B49-B61</td>\n",
       "      <td>AGGAUAGUGAAAGCUAG, GUGGUAGA, CGGGUUCGAAUCC</td>\n",
       "      <td>pz10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>675</th>\n",
       "      <td>10_0_solution_4LCK_rpr_B_57_A</td>\n",
       "      <td>4</td>\n",
       "      <td>42</td>\n",
       "      <td>A49-A54, A58-A64, B14-B22, B44-B63</td>\n",
       "      <td>GGAUAG, AAGCUAG, AGUGGUAGA, GGUCGCGGGUUCGAAUCCCG</td>\n",
       "      <td>pz10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>676</th>\n",
       "      <td>10_0_solution_4LCK_rpr_B_58_A</td>\n",
       "      <td>4</td>\n",
       "      <td>43</td>\n",
       "      <td>A59-A63, B6-B11, B13-B23, B43-B63</td>\n",
       "      <td>AGCUA, AGUAGU, CAGUGGUAGAA, GGGUCGCGGGUUCGAAUCCCG</td>\n",
       "      <td>pz10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>677</th>\n",
       "      <td>10_0_solution_4LCK_rpr_B_59_U</td>\n",
       "      <td>4</td>\n",
       "      <td>36</td>\n",
       "      <td>B6-B10, B12-B22, B44-B52, B54-B64</td>\n",
       "      <td>AGUAG, UCAGUGGUAGA, GGUCGCGGG, UCGAAUCCCGU</td>\n",
       "      <td>pz10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>678 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          filename  number_of_segments  number_of_residues  \\\n",
       "0           1_solution_0_rpr_A_4_C                   3                  20   \n",
       "1           1_solution_0_rpr_A_5_C                   3                  23   \n",
       "2           1_solution_0_rpr_A_6_G                   3                  24   \n",
       "3           1_solution_0_rpr_A_7_C                   3                  24   \n",
       "4           1_solution_0_rpr_A_8_G                   3                  24   \n",
       "..                             ...                 ...                 ...   \n",
       "673  10_0_solution_4LCK_rpr_B_55_C                   3                  32   \n",
       "674  10_0_solution_4LCK_rpr_B_56_G                   3                  38   \n",
       "675  10_0_solution_4LCK_rpr_B_57_A                   4                  42   \n",
       "676  10_0_solution_4LCK_rpr_B_58_A                   4                  43   \n",
       "677  10_0_solution_4LCK_rpr_B_59_U                   4                  36   \n",
       "\n",
       "                      nucleotide_ranges  \\\n",
       "0               A1-A8, B10-B16, B19-B23   \n",
       "1                A1-A9, B8-B15, B18-B23   \n",
       "2               A2-A10, B7-B14, B17-B23   \n",
       "3               A3-A11, B6-B13, B16-B22   \n",
       "4               A4-A12, B5-B12, B15-B21   \n",
       "..                                  ...   \n",
       "673           A48-A63, B16-B21, B50-B59   \n",
       "674           A48-A64, B15-B22, B49-B61   \n",
       "675  A49-A54, A58-A64, B14-B22, B44-B63   \n",
       "676   A59-A63, B6-B11, B13-B23, B43-B63   \n",
       "677   B6-B10, B12-B22, B44-B52, B54-B64   \n",
       "\n",
       "                                             sequences challenge_number  \n",
       "0                             CCGCCGCG, CAUGCCU, GGCGG             pz01  \n",
       "1                          CCGCCGCGC, GCCAUGCC, UGGCGG             pz01  \n",
       "2                         CGCCGCGCC, CGCCAUGC, GUGGCGG             pz01  \n",
       "3                         GCCGCGCCA, GCGCCAUG, UGUGGCG             pz01  \n",
       "4                         CCGCGCCAU, CGCGCCAU, CUGUGGC             pz01  \n",
       "..                                                 ...              ...  \n",
       "673               AGGAUAGUGAAAGCUA, UGGUAG, GGGUUCGAAU             pz10  \n",
       "674         AGGAUAGUGAAAGCUAG, GUGGUAGA, CGGGUUCGAAUCC             pz10  \n",
       "675   GGAUAG, AAGCUAG, AGUGGUAGA, GGUCGCGGGUUCGAAUCCCG             pz10  \n",
       "676  AGCUA, AGUAGU, CAGUGGUAGAA, GGGUCGCGGGUUCGAAUCCCG             pz10  \n",
       "677         AGUAG, UCAGUGGUAGA, GGUCGCGGG, UCGAAUCCCGU             pz10  \n",
       "\n",
       "[678 rows x 6 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def parse_motifs(challenges: list[str]) -> pd.DataFrame:\n",
    "    result_df = pd.DataFrame()\n",
    "    for challenge in challenges:\n",
    "        current_df = pd.read_csv(\n",
    "            DATASET_PATH / f\"{challenge}/filter-results.txt\",\n",
    "            sep=\"\\t\",\n",
    "            header=None,\n",
    "            names=[\n",
    "                \"filename\",\n",
    "                \"number_of_segments\",\n",
    "                \"number_of_residues\",\n",
    "                \"nucleotide_ranges\",\n",
    "                \"sequences\",\n",
    "            ],\n",
    "        )\n",
    "        current_df[\"challenge_number\"] = challenge\n",
    "        result_df = pd.concat([result_df, current_df])\n",
    "\n",
    "    # UWAGA! Warto ograniczyć analizy do motywów strukturalnie złożonych składających się z przynajmniej dwóch,\n",
    "    # a najlepiej trzech lub więcej segmentów.\n",
    "    result_df = result_df[result_df[\"number_of_segments\"] >= 3]\n",
    "    return result_df.reset_index(drop=True)\n",
    "\n",
    "\n",
    "motifs = parse_motifs(challenges)\n",
    "motifs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>score</th>\n",
       "      <th>solution_directory</th>\n",
       "      <th>dataset_files_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1_bujnicki_1_rpr.pdb</td>\n",
       "      <td>4.769</td>\n",
       "      <td>1_solution_0_rpr_A_4_C</td>\n",
       "      <td>resources/datasets/RNA-Puzzles/pz01/1_solution...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1_bujnicki_2_rpr.pdb</td>\n",
       "      <td>4.594</td>\n",
       "      <td>1_solution_0_rpr_A_4_C</td>\n",
       "      <td>resources/datasets/RNA-Puzzles/pz01/1_solution...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1_bujnicki_3_rpr.pdb</td>\n",
       "      <td>3.921</td>\n",
       "      <td>1_solution_0_rpr_A_4_C</td>\n",
       "      <td>resources/datasets/RNA-Puzzles/pz01/1_solution...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1_bujnicki_4_rpr.pdb</td>\n",
       "      <td>4.522</td>\n",
       "      <td>1_solution_0_rpr_A_4_C</td>\n",
       "      <td>resources/datasets/RNA-Puzzles/pz01/1_solution...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1_bujnicki_5_rpr.pdb</td>\n",
       "      <td>4.616</td>\n",
       "      <td>1_solution_0_rpr_A_4_C</td>\n",
       "      <td>resources/datasets/RNA-Puzzles/pz01/1_solution...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>10_DING_5_rpr.pdb</td>\n",
       "      <td>4.516</td>\n",
       "      <td>10_0_solution_4LCK_rpr_B_59_U</td>\n",
       "      <td>resources/datasets/RNA-Puzzles/pz10/10_0_solut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>10_DING_6_rpr.pdb</td>\n",
       "      <td>3.939</td>\n",
       "      <td>10_0_solution_4LCK_rpr_B_59_U</td>\n",
       "      <td>resources/datasets/RNA-Puzzles/pz10/10_0_solut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>10_DING_7_rpr.pdb</td>\n",
       "      <td>4.639</td>\n",
       "      <td>10_0_solution_4LCK_rpr_B_59_U</td>\n",
       "      <td>resources/datasets/RNA-Puzzles/pz10/10_0_solut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>10_DING_8_rpr.pdb</td>\n",
       "      <td>5.66</td>\n",
       "      <td>10_0_solution_4LCK_rpr_B_59_U</td>\n",
       "      <td>resources/datasets/RNA-Puzzles/pz10/10_0_solut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>10_DING_9_rpr.pdb</td>\n",
       "      <td>4.428</td>\n",
       "      <td>10_0_solution_4LCK_rpr_B_59_U</td>\n",
       "      <td>resources/datasets/RNA-Puzzles/pz10/10_0_solut...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20956 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                filename  score             solution_directory  \\\n",
       "0   1_bujnicki_1_rpr.pdb  4.769         1_solution_0_rpr_A_4_C   \n",
       "1   1_bujnicki_2_rpr.pdb  4.594         1_solution_0_rpr_A_4_C   \n",
       "2   1_bujnicki_3_rpr.pdb  3.921         1_solution_0_rpr_A_4_C   \n",
       "3   1_bujnicki_4_rpr.pdb  4.522         1_solution_0_rpr_A_4_C   \n",
       "4   1_bujnicki_5_rpr.pdb  4.616         1_solution_0_rpr_A_4_C   \n",
       "..                   ...    ...                            ...   \n",
       "21     10_DING_5_rpr.pdb  4.516  10_0_solution_4LCK_rpr_B_59_U   \n",
       "22     10_DING_6_rpr.pdb  3.939  10_0_solution_4LCK_rpr_B_59_U   \n",
       "23     10_DING_7_rpr.pdb  4.639  10_0_solution_4LCK_rpr_B_59_U   \n",
       "24     10_DING_8_rpr.pdb   5.66  10_0_solution_4LCK_rpr_B_59_U   \n",
       "25     10_DING_9_rpr.pdb  4.428  10_0_solution_4LCK_rpr_B_59_U   \n",
       "\n",
       "                                   dataset_files_path  \n",
       "0   resources/datasets/RNA-Puzzles/pz01/1_solution...  \n",
       "1   resources/datasets/RNA-Puzzles/pz01/1_solution...  \n",
       "2   resources/datasets/RNA-Puzzles/pz01/1_solution...  \n",
       "3   resources/datasets/RNA-Puzzles/pz01/1_solution...  \n",
       "4   resources/datasets/RNA-Puzzles/pz01/1_solution...  \n",
       "..                                                ...  \n",
       "21  resources/datasets/RNA-Puzzles/pz10/10_0_solut...  \n",
       "22  resources/datasets/RNA-Puzzles/pz10/10_0_solut...  \n",
       "23  resources/datasets/RNA-Puzzles/pz10/10_0_solut...  \n",
       "24  resources/datasets/RNA-Puzzles/pz10/10_0_solut...  \n",
       "25  resources/datasets/RNA-Puzzles/pz10/10_0_solut...  \n",
       "\n",
       "[20956 rows x 4 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def parse_xml_file(file_path: Path) -> pd.DataFrame:\n",
    "    tree = ET.parse(file_path)\n",
    "    root = tree.getroot()\n",
    "    return pd.DataFrame(\n",
    "        [\n",
    "            {\n",
    "                \"filename\": child.find(\"description\").find(\"filename\").text,\n",
    "                \"score\": child.find(\"score\").text,\n",
    "            }\n",
    "            for child in root\n",
    "        ]\n",
    "    )\n",
    "\n",
    "\n",
    "def parse_scores(motifs: pd.DataFrame) -> pd.DataFrame:\n",
    "    result_df = pd.DataFrame()\n",
    "    for index, row in motifs.iterrows():\n",
    "        core_path = DATASET_PATH / f\"{row['challenge_number']}\"\n",
    "        xml_path = core_path / f\"{row['filename']}-rmsd.xml\"\n",
    "\n",
    "        if xml_path.exists():\n",
    "            current_df = parse_xml_file(xml_path)\n",
    "            current_df[\"solution_directory\"] = row[\"filename\"]\n",
    "            current_df[\"dataset_files_path\"] = core_path / (\n",
    "                f\"{row['filename']}/\" + current_df[\"filename\"].apply(lambda x: x[:-4])\n",
    "            )\n",
    "            result_df = pd.concat([result_df, current_df])\n",
    "        else:\n",
    "            motifs.drop(index, inplace=True)\n",
    "\n",
    "    return result_df\n",
    "\n",
    "\n",
    "scores = parse_scores(motifs)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# # find max number of atoms in all pdb files\n",
    "# max_atoms = 0\n",
    "# for row in scores.iterrows():\n",
    "\n",
    "#     parser = PDBParser(QUIET=True)\n",
    "#     structure = parser.get_structure(\"PDB_structure\", f\"{row[1].dataset_files_path}.pdb\")\n",
    "#     for model in structure:\n",
    "#         for chain in model:\n",
    "#             for residue in chain:\n",
    "#                 n_atoms = len(residue)\n",
    "#                 max_atoms = max(max_atoms, n_atoms)\n",
    "# print(max_atoms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "def parse_pdb_file(file_path: Path) -> pd.DataFrame:\n",
    "    parser = PDBParser(QUIET=True)\n",
    "    structure = parser.get_structure(\"PDB_structure\", f\"{file_path}.pdb\")\n",
    "\n",
    "    pdb_data: list = []\n",
    "    for model in structure:\n",
    "        for chain in model:\n",
    "            for residue in chain:\n",
    "                coords_dict = {}\n",
    "                for i, atom in enumerate(residue, start=1):\n",
    "                    coords_dict[f\"x_{i}\"] = atom.coord[0]\n",
    "                    coords_dict[f\"y_{i}\"] = atom.coord[1]\n",
    "                    coords_dict[f\"z_{i}\"] = atom.coord[2]\n",
    "                \n",
    "                # padding\n",
    "                pad_len = 23*3 # max no of atoms in all structures * 3\n",
    "                if len(coords_dict) < pad_len:\n",
    "                    for i in range(len(coords_dict)+1, pad_len+1):\n",
    "                        coords_dict[f\"x_{i}\"] = np.nan\n",
    "                        coords_dict[f\"y_{i}\"] = np.nan\n",
    "                        coords_dict[f\"z_{i}\"] = np.nan\n",
    "\n",
    "                pdb_dict = {\n",
    "                    \"chain_id\": chain.id,\n",
    "                    \"residue_number\": residue.id[1],\n",
    "                    \"residue_name\": residue.resname,\n",
    "                    **coords_dict\n",
    "                }\n",
    "\n",
    "                pdb_data.append(pdb_dict)\n",
    "\n",
    "    return pd.DataFrame(pdb_data)\n",
    "\n",
    "\n",
    "def parse_tor_file(file_path: Path) -> pd.DataFrame:\n",
    "    result_df = pd.read_csv(f\"{file_path}.tor\", sep=\"\\s+\")\n",
    "    result_df.replace(\"-\", np.nan, inplace=True)\n",
    "    result_df = result_df.rename(\n",
    "        columns={\n",
    "            \"Chain\": \"chain_id\",\n",
    "            \"ResNum\": \"residue_number\",\n",
    "            \"Name\": \"residue_name\",\n",
    "            \"iCode\": \"icode\"\n",
    "        }\n",
    "    )\n",
    "    return result_df\n",
    "\n",
    "def parse_structure(file_path: Path, keep_ids: bool = False) -> pd.DataFrame:\n",
    "    pdb_df = parse_pdb_file(file_path)\n",
    "    tor_df = parse_tor_file(file_path)\n",
    "\n",
    "    result_df = pd.merge(pdb_df, tor_df, on=[\"chain_id\", \"residue_name\", \"residue_number\"])\n",
    "    # except Exception as e:\n",
    "    #     print(\"bad file: \", file_path)\n",
    "    #     raise e\n",
    "\n",
    "    if not keep_ids:\n",
    "        result_df.drop(columns=[\"chain_id\", \"residue_number\", \"residue_name\", \"icode\"], inplace=True)\n",
    "    return result_df\n",
    "\n",
    "def get_structure_features(structure_df: pd.DataFrame) -> np.ndarray:\n",
    "    # replace nans with zeros\n",
    "    structure_df.fillna(0, inplace=True)\n",
    "    structure_df = structure_df.values.flatten()\n",
    "    return structure_df\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Krótkie zapoznanie się z dostępnymi przestrzeniami reprezentacji struktur 3D RNA (przestrzenie kartezjańska i kątów torsyjnych) i ich formatami zapisu. Wybór obiecującej przestrzeni na której będziecie Państwo bazować wraz z uzasadnieniem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  chain_id  residue_number residue_name        x_1    y_1        z_1  \\\n",
      "0        A               1            C -20.322001 -0.227  69.922997   \n",
      "1        A               2            C -16.749001  2.813  72.261002   \n",
      "2        A               3            G -11.856000  3.771  74.526001   \n",
      "3        A               4            C  -6.570000  2.251  75.583000   \n",
      "4        A               5            C  -2.115000 -0.599  74.504997   \n",
      "\n",
      "         x_2    y_2        z_2        x_3  ...   y_23       z_23  icode  \\\n",
      "0 -19.306999 -1.206  71.968002 -19.379999  ...    NaN        NaN    NaN   \n",
      "1 -15.762000  0.860  73.454002 -15.702000  ...    NaN        NaN    NaN   \n",
      "2 -10.366000 -0.155  75.519997 -10.450000  ...  5.873  69.982002    NaN   \n",
      "3  -6.949000  0.074  74.462997  -5.090000  ...    NaN        NaN    NaN   \n",
      "4  -3.453000 -1.924  72.894997  -0.675000  ...    NaN        NaN    NaN   \n",
      "\n",
      "     alpha     beta    gamma   delta   epsilon     zeta      chi  \n",
      "0      NaN -176.137   59.054  81.122   -174.56  -80.489 -145.907  \n",
      "1  161.855 -159.318  166.249  89.951  -117.771   -80.79 -160.341  \n",
      "2  -73.596  158.659   64.143  82.278  -147.484  -77.638 -164.295  \n",
      "3  -75.485  171.898   62.668  83.346  -152.214  -73.751 -155.038  \n",
      "4  -78.552  172.551   62.180  81.483  -152.556  -73.703 -151.534  \n",
      "\n",
      "[5 rows x 107 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_20576/96447693.py:37: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  result_df.replace(\"-\", np.nan, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "example_path = scores[\"dataset_files_path\"].values[0]\n",
    "example_structure = parse_structure(example_path, keep_ids=True)\n",
    "print(example_structure.head())\n",
    "# example_structure = get_structure_features(example_structure)\n",
    "# print(example_structure.shape)\n",
    "# example_structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Określenie procentowych progów pozwalających podzielić dostępny zbiór danych na część treningową, walidacyjną i ewaluacyjną. Czy rozmiar dostępnego zbioru jest wystarczający? Czy należy go rozbudować? Jeśli tak to w jaki sposób?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# train-validation-test splits -> 70-15-15\n",
    "VALID_TEST_SIZE: float = 0.15\n",
    "TRAIN_SIZE: float = 1 - (2 * VALID_TEST_SIZE)\n",
    "\n",
    "assert TRAIN_SIZE > 0 and VALID_TEST_SIZE > 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Określenie sposobu reprezentacji wiedzy, którą dysponujemy (tzn. wektora cech). Czy stosowane będą techniki identyfikacji najistotniejszych cech? Jeśli tak to jakie?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=7)]: Using backend LokyBackend with 7 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20600, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_20576/96447693.py:37: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "/tmp/ipykernel_20576/96447693.py:37: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "/tmp/ipykernel_20576/96447693.py:37: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "[Parallel(n_jobs=7)]: Done   1 tasks      | elapsed:    0.6s\n",
      "/tmp/ipykernel_20576/96447693.py:37: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "[Parallel(n_jobs=7)]: Done   2 out of   7 | elapsed:    0.6s remaining:    1.4s\n",
      "/tmp/ipykernel_20576/96447693.py:37: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "/tmp/ipykernel_20576/96447693.py:37: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "[Parallel(n_jobs=7)]: Done   3 out of   7 | elapsed:    0.6s remaining:    0.8s\n",
      "/tmp/ipykernel_20576/96447693.py:37: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "[Parallel(n_jobs=7)]: Done   4 out of   7 | elapsed:    0.6s remaining:    0.5s\n",
      "/tmp/ipykernel_20576/96447693.py:37: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "[Parallel(n_jobs=7)]: Done   5 out of   7 | elapsed:    0.6s remaining:    0.3s\n",
      "/tmp/ipykernel_20576/96447693.py:37: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "/tmp/ipykernel_20576/96447693.py:37: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "[Parallel(n_jobs=7)]: Done   7 out of   7 | elapsed:    0.7s finished\n"
     ]
    }
   ],
   "source": [
    "REPRESENTATIONS_PATH = Path(\"./resources/datasets/representations\")\n",
    "STRUCTURE_DATASET_PATH = REPRESENTATIONS_PATH / \"structure_dataset.csv\"\n",
    "\n",
    "\n",
    "def prepare_structures(scores: pd.DataFrame) -> pd.DataFrame:\n",
    "    result_df = pd.DataFrame()\n",
    "    for _, row in scores.iterrows():\n",
    "        # print(row[\"dataset_files_path\"], row.name)\n",
    "        structure_df = get_structure_features(parse_structure(row[\"dataset_files_path\"]))\n",
    "        # structure_df[\"target_score\"] = row[\"score\"]\n",
    "        result_df = pd.concat([result_df, pd.Series(structure_df)])\n",
    "    return result_df\n",
    "\n",
    "\n",
    "def parallel_processing(scores: pd.DataFrame) -> pd.DataFrame:\n",
    "    cores = max(1, os.cpu_count() - 1)\n",
    "    data_splits = np.array_split(scores, cores)\n",
    "    fn = delayed(prepare_structures)\n",
    "    results = Parallel(n_jobs=cores, verbose=10)(fn(data_split) for data_split in data_splits)\n",
    "    return pd.concat(results)\n",
    "\n",
    "\n",
    "def make_structure_dataset_csv(scores: pd.DataFrame) -> None:\n",
    "    dataset = parallel_processing(scores)\n",
    "    print(dataset.shape)\n",
    "    dataset.to_csv(STRUCTURE_DATASET_PATH, index=None)\n",
    "\n",
    "# if not STRUCTURE_DATASET_PATH.exists():\n",
    "# slice scores for testing: [:10]\n",
    "make_structure_dataset_csv(scores.iloc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>target_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-20.322</td>\n",
       "      <td>-0.227</td>\n",
       "      <td>69.923</td>\n",
       "      <td>4.769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-19.307</td>\n",
       "      <td>-1.206</td>\n",
       "      <td>71.968</td>\n",
       "      <td>4.769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-19.380</td>\n",
       "      <td>0.818</td>\n",
       "      <td>69.327</td>\n",
       "      <td>4.769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-19.303</td>\n",
       "      <td>0.409</td>\n",
       "      <td>67.860</td>\n",
       "      <td>4.769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-18.016</td>\n",
       "      <td>-3.167</td>\n",
       "      <td>71.892</td>\n",
       "      <td>4.769</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        x      y       z  target_score\n",
       "0 -20.322 -0.227  69.923         4.769\n",
       "1 -19.307 -1.206  71.968         4.769\n",
       "2 -19.380  0.818  69.327         4.769\n",
       "3 -19.303  0.409  67.860         4.769\n",
       "4 -18.016 -3.167  71.892         4.769"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "structure_dataset = pd.read_csv(STRUCTURE_DATASET_PATH)\n",
    "structure_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14057501, 3), (14057501,))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def preprocess_pdb_dataset(dataset: pd.DataFrame) -> tuple[np.array, np.array]:\n",
    "    X = dataset.drop(dataset.columns[-1], axis=1)\n",
    "    y = dataset[dataset.columns[-1]]\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "def preprocess_structure_dataset(dataset: pd.DataFrame):\n",
    "    # TODO\n",
    "    return None\n",
    "\n",
    "X, y = preprocess_pdb_dataset(structure_dataset)\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Train size: (9840250, 3) [70.00%]\n",
      "    Valid size: (2108625, 3) [15.00%]\n",
      "    Test  size: (2108626, 3) [15.00%]\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "RANDOM_STATE: int = 42\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X, y, train_size=TRAIN_SIZE, random_state=RANDOM_STATE\n",
    ")\n",
    "X_valid, X_test, y_valid, y_test = train_test_split(\n",
    "    X_valid, y_valid, test_size=0.5, random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "print(\n",
    "    f\"\"\"\n",
    "    Train size: {X_train.shape} [{X_train.shape[0] / X.shape[0] * 100:.2f}%]\n",
    "    Valid size: {X_valid.shape} [{X_valid.shape[0] / X.shape[0] * 100:.2f}%]\n",
    "    Test  size: {X_test.shape} [{X_test.shape[0] / X.shape[0] * 100:.2f}%]\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Wybór obiecujących technik uczenia maszynowego, które uważacie Państwo, że powinny się sprawdzić podczas rozwiązywania postawionego problemu wraz z uzasadnieniem (np. głębokie sieci neuronowe, SVM, RandomForest ,itd.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.71125561825804"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dummy approach\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "\n",
    "regr = RandomForestRegressor(n_jobs=-1, random_state=RANDOM_STATE)\n",
    "regr.fit(X_train, y_train)\n",
    "\n",
    "y_pred = regr.predict(X_test)\n",
    "rf_score = root_mean_squared_error(y_test, y_pred)\n",
    "rf_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Iteracyjne przeprowadzenie procesu uczenia, określenie wartości parametrów kluczowych dla tego procesu (np. zastosowana funkcja straty, learning rate, optimizer, itd.) i wskazanie czy natrafiliście Państwo na jakieś problemy podczas tego procesu np. przeuczenie i jak Państwo sobie z tymi problemami poradziliście o ile rzeczywiście wystąpiły?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Optymalizacja wartości hiperparametrów – czy warto je optymalizować w przypadku rozpatrywanego problemu? Jeśli tak to w jaki sposób?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Wybór i uzasadnienie zastosowanych miar oceny, przeprowadzenie procesu ewaluacji uzyskanego(ych) modelu(i), podsumowanie i analiza uzyskanych wyników."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
