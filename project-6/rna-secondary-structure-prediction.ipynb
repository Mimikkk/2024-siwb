{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projekt 6: Przewidywanie struktury drugorzÄ™dowej RNA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-14T12:00:39.626260912Z",
     "start_time": "2024-05-14T12:00:39.622802710Z"
    }
   },
   "outputs": [],
   "source": [
    "# %pip install matplotlib pandas seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-14T12:00:39.662757974Z",
     "start_time": "2024-05-14T12:00:39.624808934Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from collections import defaultdict\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "DatasetDirectory = Path(\"./resources/datasets\")\n",
    "ModelDirectory = Path(\"./resources/models\")\n",
    "ResultsDirectory = Path(\"./resources/results\")\n",
    "FiguresDirectory = Path(\"./resources/figures\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-14T12:00:39.663890373Z",
     "start_time": "2024-05-14T12:00:39.662611169Z"
    }
   },
   "outputs": [],
   "source": [
    "def split_datasets(\n",
    "    path: Path, train_ratio: float = 0.7, valid_ratio: float = 0.15, test_ratio: float = 0.15\n",
    ") -> None:\n",
    "    random.seed(42)\n",
    "    files = [f\"{path}/{f}\" for f in os.listdir(path) if f.endswith(\".bpseq\")]\n",
    "    random.shuffle(files)\n",
    "\n",
    "    total_files = len(files)\n",
    "    train_count = int(total_files * train_ratio)\n",
    "    valid_count = int(total_files * valid_ratio)\n",
    "\n",
    "    train_files = files[:train_count]\n",
    "    valid_files = files[train_count : train_count + valid_count]\n",
    "    test_files = files[train_count + valid_count :]\n",
    "\n",
    "    with open(f\"{path}-train-bpseq.lst\", \"w\") as f:\n",
    "        f.write(\"\\n\".join(train_files))\n",
    "    with open(f\"{path}-valid-bpseq.lst\", \"w\") as f:\n",
    "        f.write(\"\\n\".join(valid_files))\n",
    "    with open(f\"{path}-test-bpseq.lst\", \"w\") as f:\n",
    "        f.write(\"\\n\".join(test_files))\n",
    "\n",
    "    with open(f\"{path}-train-fa.lst\", \"w\") as f:\n",
    "        f.write(\"\\n\".join(train_files).replace(\".bpseq\", \".fa\"))\n",
    "    with open(f\"{path}-valid-fa.lst\", \"w\") as f:\n",
    "        f.write(\"\\n\".join(valid_files).replace(\".bpseq\", \".fa\"))\n",
    "    with open(f\"{path}-test-fa.lst\", \"w\") as f:\n",
    "        f.write(\"\\n\".join(test_files).replace(\".bpseq\", \".fa\"))\n",
    "\n",
    "\n",
    "def datasets_sanity_check() -> None:\n",
    "    lst_files = [file for file in os.listdir(DatasetDirectory) if file.endswith(\".lst\")]\n",
    "\n",
    "    for file in lst_files:\n",
    "        file_path = DatasetDirectory / file\n",
    "        with open(file_path, \"r\") as f:\n",
    "            lines = f.readlines()\n",
    "        num_lines = len(lines)\n",
    "\n",
    "        total_files = len(os.listdir(DatasetDirectory / file.split(\"-\")[0])) // 2\n",
    "        print(f\"{file:<25} has {round(num_lines/total_files * 100)}% files ({num_lines})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-14T12:00:39.808665262Z",
     "start_time": "2024-05-14T12:00:39.662939985Z"
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'resources/datasets/ArchiveII'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[4], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43msplit_datasets\u001B[49m\u001B[43m(\u001B[49m\u001B[43mDATASET_DIR\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m/\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mArchiveII\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m      2\u001B[0m split_datasets(DATASET_DIR \u001B[38;5;241m/\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mPDB\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m      3\u001B[0m datasets_sanity_check()\n",
      "Cell \u001B[0;32mIn[3], line 5\u001B[0m, in \u001B[0;36msplit_datasets\u001B[0;34m(path, train_ratio, valid_ratio, test_ratio)\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21msplit_datasets\u001B[39m(\n\u001B[1;32m      2\u001B[0m     path: Path, train_ratio: \u001B[38;5;28mfloat\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0.7\u001B[39m, valid_ratio: \u001B[38;5;28mfloat\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0.15\u001B[39m, test_ratio: \u001B[38;5;28mfloat\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0.15\u001B[39m\n\u001B[1;32m      3\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m      4\u001B[0m     random\u001B[38;5;241m.\u001B[39mseed(\u001B[38;5;241m42\u001B[39m)\n\u001B[0;32m----> 5\u001B[0m     files \u001B[38;5;241m=\u001B[39m [\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mpath\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m/\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mf\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m f \u001B[38;5;129;01min\u001B[39;00m \u001B[43mos\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlistdir\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpath\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mif\u001B[39;00m f\u001B[38;5;241m.\u001B[39mendswith(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m.bpseq\u001B[39m\u001B[38;5;124m\"\u001B[39m)]\n\u001B[1;32m      6\u001B[0m     random\u001B[38;5;241m.\u001B[39mshuffle(files)\n\u001B[1;32m      8\u001B[0m     total_files \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlen\u001B[39m(files)\n",
      "\u001B[0;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: 'resources/datasets/ArchiveII'"
     ]
    }
   ],
   "source": [
    "split_datasets(DatasetDirectory / \"ArchiveII\")\n",
    "split_datasets(DatasetDirectory / \"PDB\")\n",
    "datasets_sanity_check()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ArchiveII Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-14T12:00:39.811203763Z",
     "start_time": "2024-05-14T12:00:39.809914670Z"
    }
   },
   "outputs": [],
   "source": [
    "GpuCount: int = -1\n",
    "EpochCount: int = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-14T12:00:39.818312576Z",
     "start_time": "2024-05-14T12:00:39.812842539Z"
    }
   },
   "outputs": [],
   "source": [
    "DatasetName = \"ArchiveII\"\n",
    "!mxfold2 train {DATASET_DIR}/{DATASET_NAME}-train-bpseq.lst \\\n",
    "    --param {ModelDirectory} / {DatasetName} - model.pth - -save - config {ModelDirectory} / {DatasetName} - model.conf \\\n",
    "                                                                          - -gpu {GpuCount} - -epoch {EpochCount}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-05-14T12:00:39.814901402Z"
    }
   },
   "outputs": [],
   "source": [
    "DatasetName = \"ArchiveII\"\n",
    "!mxfold2 predict @./{MODELS_DIR}/{DATASET_NAME}-model.conf {DATASET_DIR}/{DATASET_NAME}-test-bpseq.lst \\\n",
    "    --bpseq {ResultsDirectory} / {DatasetName} - -result {ResultsDirectory} / {DatasetName} - results.csv \\\n",
    "                                                         - -gpu {GpuCount}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PDB Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-05-14T12:00:39.816999980Z"
    }
   },
   "outputs": [],
   "source": [
    "DatasetName = \"PDB\"\n",
    "!mxfold2 train {DATASET_DIR}/{DATASET_NAME}-train-bpseq.lst \\\n",
    "    --param {ModelDirectory} / {DatasetName} - model.pth - -save - config {ModelDirectory} / {DatasetName} - model.conf \\\n",
    "                                                                          - -gpu {GpuCount} - -epoch {EpochCount}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-14T12:00:39.826938359Z",
     "start_time": "2024-05-14T12:00:39.818692628Z"
    }
   },
   "outputs": [],
   "source": [
    "DatasetName = \"PDB\"\n",
    "!mxfold2 predict @./{MODELS_DIR}/{DATASET_NAME}-model.conf {DATASET_DIR}/{DATASET_NAME}-test-bpseq.lst \\\n",
    "    --bpseq {ResultsDirectory} / {DatasetName} - -result {ResultsDirectory} / {DatasetName} - results.csv \\\n",
    "                                                         - -gpu {GpuCount}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer Learning (ArchiveII -> PDB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-05-14T12:00:39.845356457Z"
    }
   },
   "outputs": [],
   "source": [
    "DatasetName = \"PDB\"\n",
    "!mxfold2 train @./{MODELS_DIR}/ArchiveII-model.conf {DATASET_DIR}/{DATASET_NAME}-train-bpseq.lst --init-param {MODELS_DIR}/ArchiveII-model.pth \\\n",
    "    --param {ModelDirectory} / TransferLearning - model.pth - -save - config {ModelDirectory} / TransferLearning - model.conf \\\n",
    "                                                                             - -gpu {GpuCount} - -epoch {EpochCount}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-05-14T12:00:39.845637483Z"
    }
   },
   "outputs": [],
   "source": [
    "DatasetName = \"PDB\"\n",
    "!mxfold2 predict @./resources/models/TransferLearning-model.conf {DATASET_DIR}/{DATASET_NAME}-test-bpseq.lst \\\n",
    "    --bpseq {ResultsDirectory} / TransferLearning - -result {ResultsDirectory} / TransferLearning - results.csv \\\n",
    "                                                            - -gpu {GpuCount}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-05-14T12:00:39.845901718Z"
    }
   },
   "outputs": [],
   "source": [
    "columns: list[str] = [\n",
    "    \"filename\",\n",
    "    \"sequence_length\",\n",
    "    \"elapsed_time\",\n",
    "    \"sc\",\n",
    "    \"tp\",\n",
    "    \"tn\",\n",
    "    \"fp\",\n",
    "    \"fn\",\n",
    "    \"sen\",\n",
    "    \"ppv\",\n",
    "    \"fval\",\n",
    "    \"mcc\",\n",
    "]\n",
    "\n",
    "results = pd.read_csv(ResultsDirectory / \"ArchiveII-results.csv\", header=None, names=columns)\n",
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-05-14T12:00:39.846185439Z"
    }
   },
   "outputs": [],
   "source": [
    "def calculate_metrics(results: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Calculate the metrics for the given results: INF, PPV, TPR, TNR.\"\"\"\n",
    "    tp_sum, tn_sum, fp_sum, fn_sum = results[[\"tp\", \"tn\", \"fp\", \"fn\"]].sum()\n",
    "    ppv = tp_sum / (tp_sum + fp_sum)\n",
    "    tpr = tp_sum / (tp_sum + fn_sum)\n",
    "    inf = (ppv * tpr) ** 0.5\n",
    "    tnr = tn_sum / (tn_sum + fp_sum)\n",
    "    return inf, ppv, tpr, tnr\n",
    "\n",
    "\n",
    "def plot_metrics(datasets: tuple[str]) -> None:\n",
    "    \"\"\"Plot the metrics for the given results.\"\"\"\n",
    "    metrics = defaultdict(dict)\n",
    "    for dataset in datasets:\n",
    "        df = pd.read_csv(ResultsDirectory / f\"{dataset}-results.csv\", header=None, names=columns)\n",
    "        inf, ppv, tpr, tnr = calculate_metrics(df)\n",
    "        metrics[\"inf\"].update({dataset: inf})\n",
    "        metrics[\"ppv\"].update({dataset: ppv})\n",
    "        metrics[\"tpr\"].update({dataset: tpr})\n",
    "        metrics[\"tnr\"].update({dataset: tnr})\n",
    "\n",
    "    colors = sns.color_palette(\"magma\", 3)\n",
    "    fig, axs = plt.subplots(2, 2, figsize=(12, 8), tight_layout=True)\n",
    "    ax1, ax2, ax3, ax4 = axs.flatten()\n",
    "\n",
    "    ax1.set_title(\"INF\")\n",
    "    ax1.bar(metrics[\"inf\"].keys(), metrics[\"inf\"].values(), color=colors, label=\"INF\")\n",
    "    ax1.grid(axis=\"y\", linestyle=\"--\", alpha=0.25)\n",
    "    ax1.set_xlabel(\"dataset\")\n",
    "    ax1.set_ylabel(\"score\")\n",
    "\n",
    "    ax2.set_title(\"PPV\")\n",
    "    ax2.bar(metrics[\"ppv\"].keys(), metrics[\"ppv\"].values(), color=colors, label=\"PPV\")\n",
    "    ax2.grid(axis=\"y\", linestyle=\"--\", alpha=0.25)\n",
    "    ax2.set_xlabel(\"dataset\")\n",
    "    ax2.set_ylabel(\"score\")\n",
    "\n",
    "    ax3.set_title(\"TPR\")\n",
    "    ax3.bar(metrics[\"tpr\"].keys(), metrics[\"tpr\"].values(), color=colors, label=\"TPR\")\n",
    "    ax3.grid(axis=\"y\", linestyle=\"--\", alpha=0.25)\n",
    "    ax3.set_xlabel(\"dataset\")\n",
    "    ax3.set_ylabel(\"score\")\n",
    "\n",
    "    ax4.set_title(\"TNR\")\n",
    "    ax4.bar(metrics[\"tnr\"].keys(), metrics[\"tnr\"].values(), color=colors, label=\"TNR\")\n",
    "    ax4.grid(axis=\"y\", linestyle=\"--\", alpha=0.25)\n",
    "    ax4.set_xlabel(\"dataset\")\n",
    "    ax4.set_ylabel(\"score\")\n",
    "\n",
    "    fig.savefig(FiguresDirectory / \"results.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-05-14T12:00:39.846462968Z"
    }
   },
   "outputs": [],
   "source": [
    "datasets = (\"ArchiveII\", \"PDB\", \"TransferLearning\")\n",
    "\n",
    "plot_metrics(datasets)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
