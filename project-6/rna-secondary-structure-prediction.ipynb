{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projekt 6: Przewidywanie struktury drugorzędowej RNA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-14T12:50:47.575905715Z",
     "start_time": "2024-05-14T12:50:47.566254472Z"
    }
   },
   "outputs": [],
   "source": [
    "# %pip install matplotlib pandas seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-14T12:50:47.603463280Z",
     "start_time": "2024-05-14T12:50:47.582912838Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from collections import defaultdict\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "DatasetDirectory = Path(\"./resources/datasets\")\n",
    "ModelDirectory = Path(\"./resources/models\")\n",
    "ResultsDirectory = Path(\"./resources/results\")\n",
    "FiguresDirectory = Path(\"./resources/figures\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-14T12:50:47.606512342Z",
     "start_time": "2024-05-14T12:50:47.595286088Z"
    }
   },
   "outputs": [],
   "source": [
    "def split_datasets(\n",
    "    path: Path, train_ratio: float = 0.7, valid_ratio: float = 0.15, test_ratio: float = 0.15\n",
    ") -> None:\n",
    "  random.seed(42)\n",
    "  files = [f\"{path}/{f}\" for f in os.listdir(path) if f.endswith(\".bpseq\")]\n",
    "  random.shuffle(files)\n",
    "\n",
    "  total_files = len(files)\n",
    "  train_count = int(total_files * train_ratio)\n",
    "  valid_count = int(total_files * valid_ratio)\n",
    "\n",
    "  train_files = files[:train_count]\n",
    "  valid_files = files[train_count: train_count + valid_count]\n",
    "  test_files = files[train_count + valid_count:]\n",
    "\n",
    "  with open(f\"{path}-train-bpseq.lst\", \"w\") as f:\n",
    "    f.write(\"\\n\".join(train_files))\n",
    "  with open(f\"{path}-valid-bpseq.lst\", \"w\") as f:\n",
    "    f.write(\"\\n\".join(valid_files))\n",
    "  with open(f\"{path}-test-bpseq.lst\", \"w\") as f:\n",
    "    f.write(\"\\n\".join(test_files))\n",
    "\n",
    "  with open(f\"{path}-train-fa.lst\", \"w\") as f:\n",
    "    f.write(\"\\n\".join(train_files).replace(\".bpseq\", \".fa\"))\n",
    "  with open(f\"{path}-valid-fa.lst\", \"w\") as f:\n",
    "    f.write(\"\\n\".join(valid_files).replace(\".bpseq\", \".fa\"))\n",
    "  with open(f\"{path}-test-fa.lst\", \"w\") as f:\n",
    "    f.write(\"\\n\".join(test_files).replace(\".bpseq\", \".fa\"))\n",
    "\n",
    "\n",
    "def datasets_sanity_check() -> None:\n",
    "  lst_files = [file for file in os.listdir(DatasetDirectory) if file.endswith(\".lst\")]\n",
    "\n",
    "  for file in lst_files:\n",
    "    file_path = DatasetDirectory / file\n",
    "    with open(file_path, \"r\") as f:\n",
    "      lines = f.readlines()\n",
    "    num_lines = len(lines)\n",
    "\n",
    "    total_files = len(os.listdir(DatasetDirectory / file.split(\"-\")[0])) // 2\n",
    "    print(f\"{file:<25} has {round(num_lines / total_files * 100)}% files ({num_lines})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-14T12:50:47.701215513Z",
     "start_time": "2024-05-14T12:50:47.604177313Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ArchiveII-train-bpseq.lst has 70% files (2779)\n",
      "ArchiveII-valid-bpseq.lst has 15% files (595)\n",
      "ArchiveII-test-bpseq.lst  has 15% files (596)\n",
      "ArchiveII-train-fa.lst    has 70% files (2779)\n",
      "ArchiveII-valid-fa.lst    has 15% files (595)\n",
      "ArchiveII-test-fa.lst     has 15% files (596)\n",
      "PDB-train-bpseq.lst       has 70% files (415)\n",
      "PDB-valid-bpseq.lst       has 15% files (89)\n",
      "PDB-test-bpseq.lst        has 15% files (90)\n",
      "PDB-train-fa.lst          has 70% files (415)\n",
      "PDB-valid-fa.lst          has 15% files (89)\n",
      "PDB-test-fa.lst           has 15% files (90)\n"
     ]
    }
   ],
   "source": [
    "split_datasets(DatasetDirectory / \"ArchiveII\")\n",
    "split_datasets(DatasetDirectory / \"PDB\")\n",
    "datasets_sanity_check()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ArchiveII Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "GpuCount: int = 1\n",
    "EpochCount: int = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "DatasetName = \"ArchiveII\"\n",
    "Command = f\"\"\"\n",
    "mxfold2 train \\\n",
    "  {DatasetDirectory}/{DatasetName}-train-bpseq.lst \\\n",
    "  --param {ModelDirectory}/{DatasetName}-model.pth \\\n",
    "  --save-config {ModelDirectory}/{DatasetName}-model.conf \\\n",
    "  --gpu {GpuCount} \\\n",
    "  --epoch {EpochCount}\n",
    "\"\"\"\n",
    "!{Command}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-14T13:00:30.159651554Z",
     "start_time": "2024-05-14T13:00:28.957596795Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: mxfold2 [-h] {train,predict} ...\r\n",
      "mxfold2: error: unrecognized arguments: / ArchiveII-results.csv\r\n"
     ]
    }
   ],
   "source": [
    "DatasetName = \"ArchiveII\"\n",
    "Command = f\"\"\"\n",
    "mxfold2 predict \\\n",
    "  @./{ModelDirectory}/{DatasetName}-model.conf \\\n",
    "  {DatasetDirectory}/{DatasetName}-test-bpseq.lst \\\n",
    "  --bpseq {ResultsDirectory}/{DatasetName} \\\n",
    "  --result {ResultsDirectory}/{DatasetName}-results.csv \\\n",
    "  --gpu {GpuCount}\n",
    "\n",
    "\"\"\"\n",
    "!{Command}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PDB Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2024-05-14T13:00:30.159920206Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  2%|▍                    | 8/415 [00:16<55:20,  8.16s/it, train_loss=1.336e-01]"
     ]
    }
   ],
   "source": [
    "DatasetName = \"PDB\"\n",
    "Command = f\"\"\"\n",
    "mxfold2 train \\\n",
    "  {DatasetDirectory}/{DatasetName}-train-bpseq.lst \\\n",
    "  --param {ModelDirectory}/{DatasetName}-model.pth \\\n",
    "  --save-config {ModelDirectory}/{DatasetName}-model.conf \\\n",
    "  --gpu {GpuCount} \\\n",
    "  --epoch {EpochCount}\n",
    "\"\"\"\n",
    "!{Command}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "DatasetName = \"PDB\"\n",
    "Command = f\"\"\"\n",
    "mxfold2 predict \\\n",
    "  @./{ModelDirectory}/{DatasetName}-model.conf \\\n",
    "  {DatasetDirectory}/{DatasetName}-test-bpseq.lst \\\n",
    "  --bpseq {ResultsDirectory}/{DatasetName} \\\n",
    "  --result {ResultsDirectory}/{DatasetName}-results.csv \\\n",
    "  --gpu {GpuCount}\n",
    "\"\"\"\n",
    "\n",
    "!{Command}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer Learning (ArchiveII -> PDB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "DatasetName = \"PDB\"\n",
    "Command = f\"\"\"\n",
    "mxfold2 train \\\n",
    "  @./{ModelDirectory}/ArchiveII-model.conf \\\n",
    "  {DatasetDirectory}/{DatasetName}-train-bpseq.lst \\\n",
    "  --init-param {ModelDirectory}/ArchiveII-model.pth \\\n",
    "  --param {ModelDirectory}/TransferLearning-model.pth \\\n",
    "  --save-config {ModelDirectory}/TransferLearning-model.conf \\\n",
    "  --gpu {GpuCount} \\\n",
    "  --epoch {EpochCount}\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "DatasetName = \"PDB\"\n",
    "Command = f\"\"\"\n",
    "mxfold2 predict \\\n",
    "  @./{ModelDirectory}/TransferLearning-model.conf \\\n",
    "  {DatasetDirectory}/{DatasetName}-test-bpseq.lst \\\n",
    "  --bpseq {ResultsDirectory}/TransferLearning \\\n",
    "  --result {ResultsDirectory}/TransferLearning-results.csv \\\n",
    "  --gpu {GpuCount}\n",
    "\"\"\"\n",
    "!{Command}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "columns: list[str] = [\n",
    "  \"filename\",\n",
    "  \"sequence_length\",\n",
    "  \"elapsed_time\",\n",
    "  \"sc\",\n",
    "  \"tp\",\n",
    "  \"tn\",\n",
    "  \"fp\",\n",
    "  \"fn\",\n",
    "  \"sen\",\n",
    "  \"ppv\",\n",
    "  \"fval\",\n",
    "  \"mcc\",\n",
    "]\n",
    "\n",
    "results = pd.read_csv(ResultsDirectory / \"ArchiveII-results.csv\", header=None, names=columns)\n",
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "def calculate_metrics(results: pd.DataFrame) -> pd.DataFrame:\n",
    "  \"\"\"Calculate the metrics for the given results: INF, PPV, TPR, TNR.\"\"\"\n",
    "  tp_sum, tn_sum, fp_sum, fn_sum = results[[\"tp\", \"tn\", \"fp\", \"fn\"]].sum()\n",
    "  ppv = tp_sum / (tp_sum + fp_sum)\n",
    "  tpr = tp_sum / (tp_sum + fn_sum)\n",
    "  inf = (ppv * tpr) ** 0.5\n",
    "  tnr = tn_sum / (tn_sum + fp_sum)\n",
    "  return inf, ppv, tpr, tnr\n",
    "\n",
    "\n",
    "def plot_metrics(datasets: tuple[str]) -> None:\n",
    "  \"\"\"Plot the metrics for the given results.\"\"\"\n",
    "  metrics = defaultdict(dict)\n",
    "  for dataset in datasets:\n",
    "    df = pd.read_csv(ResultsDirectory / f\"{dataset}-results.csv\", header=None, names=columns)\n",
    "    inf, ppv, tpr, tnr = calculate_metrics(df)\n",
    "    metrics[\"inf\"].update({dataset: inf})\n",
    "    metrics[\"ppv\"].update({dataset: ppv})\n",
    "    metrics[\"tpr\"].update({dataset: tpr})\n",
    "    metrics[\"tnr\"].update({dataset: tnr})\n",
    "\n",
    "  colors = sns.color_palette(\"magma\", 3)\n",
    "  fig, axs = plt.subplots(2, 2, figsize=(12, 8), tight_layout=True)\n",
    "  ax1, ax2, ax3, ax4 = axs.flatten()\n",
    "\n",
    "  ax1.set_title(\"INF\")\n",
    "  ax1.bar(metrics[\"inf\"].keys(), metrics[\"inf\"].values(), color=colors, label=\"INF\")\n",
    "  ax1.grid(axis=\"y\", linestyle=\"--\", alpha=0.25)\n",
    "  ax1.set_xlabel(\"dataset\")\n",
    "  ax1.set_ylabel(\"score\")\n",
    "\n",
    "  ax2.set_title(\"PPV\")\n",
    "  ax2.bar(metrics[\"ppv\"].keys(), metrics[\"ppv\"].values(), color=colors, label=\"PPV\")\n",
    "  ax2.grid(axis=\"y\", linestyle=\"--\", alpha=0.25)\n",
    "  ax2.set_xlabel(\"dataset\")\n",
    "  ax2.set_ylabel(\"score\")\n",
    "\n",
    "  ax3.set_title(\"TPR\")\n",
    "  ax3.bar(metrics[\"tpr\"].keys(), metrics[\"tpr\"].values(), color=colors, label=\"TPR\")\n",
    "  ax3.grid(axis=\"y\", linestyle=\"--\", alpha=0.25)\n",
    "  ax3.set_xlabel(\"dataset\")\n",
    "  ax3.set_ylabel(\"score\")\n",
    "\n",
    "  ax4.set_title(\"TNR\")\n",
    "  ax4.bar(metrics[\"tnr\"].keys(), metrics[\"tnr\"].values(), color=colors, label=\"TNR\")\n",
    "  ax4.grid(axis=\"y\", linestyle=\"--\", alpha=0.25)\n",
    "  ax4.set_xlabel(\"dataset\")\n",
    "  ax4.set_ylabel(\"score\")\n",
    "\n",
    "  fig.savefig(FiguresDirectory / \"results.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "datasets = (\"ArchiveII\", \"PDB\", \"TransferLearning\")\n",
    "\n",
    "plot_metrics(datasets)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
