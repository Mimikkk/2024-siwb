{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ad6c90baa0dc1a1",
   "metadata": {},
   "source": [
    "# Eksperymenty z modelami opisujące profile pacjentów "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "259817bb4f94a937",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-27T17:37:23.761236Z",
     "start_time": "2024-05-27T17:37:23.757371Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from typing import NamedTuple, List\n",
    "from textwrap import wrap\n",
    "from matplotlib import pyplot as plt\n",
    "from stable_baselines3 import PPO, A2C, DQN\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a3e4b075d8be6bca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-27T17:37:23.872761Z",
     "start_time": "2024-05-27T17:37:23.869081Z"
    }
   },
   "outputs": [],
   "source": [
    "from environment.profiles import profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6e5738d7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-27T17:37:23.893924Z",
     "start_time": "2024-05-27T17:37:23.890251Z"
    }
   },
   "outputs": [],
   "source": [
    "from environment.fogg_behavioural_model import Patient"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dd7c54343289da7",
   "metadata": {},
   "source": [
    "## Parametry eksperymentu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b401c3c64ab3ecf3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-27T17:37:23.925416Z",
     "start_time": "2024-05-27T17:37:23.922355Z"
    }
   },
   "outputs": [],
   "source": [
    "UpdatedEveryDayHours = 24\n",
    "WeekHours = 7 * UpdatedEveryDayHours\n",
    "ThreeWeeksHours = WeekHours * 3\n",
    "EightWeeksHours = WeekHours * 8\n",
    "FiveWeeksHours = WeekHours * 5\n",
    "\n",
    "Condition = 'stable'\n",
    "Habituation = False\n",
    "#very high e.g. 9999999999 to make it outside of the intervention time...effectively no preference shift\n",
    "TimePreferenceUpdateStep = 9999999999999999\n",
    "# 500 runs in the paper\n",
    "RunCount = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fb010225b43237b0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-27T17:37:23.930818Z",
     "start_time": "2024-05-27T17:37:23.926700Z"
    }
   },
   "outputs": [],
   "source": [
    "ResultsDirectory = 'results'\n",
    "if not os.path.exists(ResultsDirectory):\n",
    "  os.makedirs(ResultsDirectory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "230b135acb8aa618",
   "metadata": {},
   "source": [
    "## Opisy profili\n",
    "Na podstawie 5 pytań oraz odpowiedzi zagregowanych w tabeli 1 dla poszczególnych profili wyróżniliśmy 4 cechy charakterystyczne, które pozwalają zamodelować różnice pomiędzy profilami i nadać im nazwy. Są to:\n",
    "\n",
    "  * responsiveness - cecha agregująca pytania 4 i 5, dotyczy gotowości pacjenta do wykonania zaleconej przez system aktywności. Przyjmuje ona wartości z zakresu [-2, 0] i jest obliczana na podstawie wartości cech \"stress\" oraz \"tiredness\". Wartość \"stress\" jest obliczana jako różnica \"arousal\" oraz \"valence\", gdzie zgodnie z Markov et al. (2019) w \"arousal-valence emotion space\" stres jest tym większy, im większa wartość \"arousal\" i im mniejsza wartość \"valence\". Wartość \"tiredness\" bierze pod uwagę 2 czynniki: liczbę przespanych godzin w nocy oraz ile godzin pacjent jest na nogach.\n",
    " * motivation - dotyczy sytuacji, gdy pacjent lubi pokonywać swój własny rekord. Przyjmuje wartości z zakresu [0,1] i śledzi ostatnie 10 reakcji na powiadomienia o aktywności. Im więcej razy pacjent pozytywnie zareagował na powiadomienie, tym bardziej ma ochotę nie popsuć swojej dobrej passy. Wykorzystaliśmy do tego metodę _update_patients_activity_score().\n",
    "\n",
    " \n",
    "Trudniejsze do zamodelowania okazały się cechy \"peer_competition\" oraz \"peer_comparison\" ze względu na konieczność symulacji zachowania grupy rówieśników, a nie tylko jednego pacjenta:\n",
    "\n",
    " * peer_competition - wartości losowane ze zbioru {0,1}, poza sytuacją, gdy pacjent jest w domu i nie ma kontaktu z rówieśnikami.\n",
    " * peer_comparison - cecha modelująca sytuację, w której pacjent czuje się lepiej, gdy jest lepszy od rówieśników, losowana podczas każdego kroku algorytmu ze zbioru {0,1}.\n",
    "\n",
    "### Profil 0 - Indifferent:\n",
    "Pacjenci z tej grupy nie wykazują entuzjazmu zarówno w aspekcie samodoskonalenia, jak i rywalizacji społecznej, wskazując na preferowanie samodzielnych działań bez zewnętrznych nacisków. Z drugiej strony nie wpływa na nich negatywnie stres oraz zmęczenie. Na tle wyróżnionych charakterystyk nie przyjmują żadnych skrajnych wartości.\n",
    "\n",
    "### Profil 1 - Stressed:\n",
    "Pacjenci ci nie reagują dobrze na interwencje w stresujących momentach, co sugeruje, że ich interakcje powinny być zaplanowane w chwilach spokoju. Będą oni tracić chęć odpowiedzi na powiadomienia zarówno w sytuacji, gdy są zmęczeni, jak i wtedy, kiedy są zestresowani. To ich odróżnia od profilu zerowego. Ta cecha jest zamodelowana poprzez odjęcie wartości maksymalnej z cech *stress* oraz *tiredness* -> max(*stress*, *tiredness*).\n",
    "\n",
    "### Profil 2 - Motivated:\n",
    "Na motywację tej grupy pacjentów wpływają zarówno pozytywne, jak i negatywne bodźce. Jest zmotywowana widocznymi postępami i osiągnięciami, korzysta z funkcji, które śledzą i wyświetlają ich postępy zdrowotne oraz zwiększają ich zaangażowanie poprzez namacalne wyniki (cecha motivation). Algorytm uczenia agenta odbiera to jako dodatkowe punkty z wartości *peer_competition*, *peer_comparison* oraz *motivation* przy obliczaniu zachowania na podstawie modelu Fogga. W tym samym czasie ci pacjenci mogą tracić \"punkty\" ze względu na stres i zmęczenie, podobnie jak pacjenci z profilu pierwszego.\n",
    "\n",
    "### Profil 3 Responsive:\n",
    "Ta grupa pacjentów powinna najlepiej się odnaleźć w środowisku adaptacyjnych interwencji. Ich własny postęp jest dla nich motywacją (cecha motivation). Mogą oni też czerpać zyski z rywalizacji z innymi. Wpływ stresu nie jest aż tak wyraźny w ich przypadku. Mimo wszystko algorytm musi brać pod uwagę, że nie będą dobrze odpowiadać na powiadomienia w sytuacji, gdy są zmęczeni. Aby odzwierciedlić neutralną odpowiedź na pytania 1, 3 oraz 4, przemnożono odpowiadające tym pytaniom cechy (Q1 - *self.peer_comparison*, Q3 - *self.peer_competition*, Q4 - *self.tiredness*) przez 0.5.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3491eabb5a069453",
   "metadata": {},
   "source": [
    "\n",
    "## Metody przedstawienia wyników"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "126410b62f42eedd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-27T17:37:23.950048Z",
     "start_time": "2024-05-27T17:37:23.946267Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "class ExperimentResult(NamedTuple):\n",
    "  sleep_hours: List[float]\n",
    "  positive_mood_hours: List[float]\n",
    "  response_ratios: List[float]\n",
    "  notifications: List[float]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b18fc49b4d9ca3df",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-27T17:37:23.977149Z",
     "start_time": "2024-05-27T17:37:23.966969Z"
    }
   },
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "\n",
    "def plot_experiment_result_hours(result: ExperimentResult):\n",
    "  (sleeps_hours, positive_moods_hours, _, _) = result\n",
    "\n",
    "  plt.figure(figsize=(8, 5))\n",
    "  plt.plot(np.nanmean(sleeps_hours, axis=0), label='Hours slept', color='r')\n",
    "  plt.plot(np.mean(positive_moods_hours, axis=0), label='Hours in positive mood')\n",
    "  plt.ylabel('Hours ')\n",
    "  plt.xlabel('Intervention Days')\n",
    "  plt.legend()\n",
    "  plt.show()\n",
    "\n",
    "def plot_experiment_result_ratios(result: ExperimentResult):\n",
    "  (_, _, ratios, notifications) = result\n",
    "\n",
    "  _, (ratios_axis, notifications_axis) = plt.subplots(2, 1, sharex=True, sharey=False, figsize=(10, 8))\n",
    "  ratios_axis.plot(np.nanmean(ratios, axis=0), label='response ratio', color='r')\n",
    "  notifications_axis.plot(np.nanmean(notifications, axis=0), label='num of notifications')\n",
    "  notifications_axis.set_xlabel('Intervention days')\n",
    "  notifications_axis.set_ylabel('No. of notifications')\n",
    "  ratios_axis.set_ylabel('Response ratio')\n",
    "  plt.show()\n",
    "\n",
    "class ReadResult(NamedTuple):\n",
    "  ratios: List[float]\n",
    "  notifications: List[float]\n",
    "\n",
    "def read_ratios_and_notifications(name: str, epoch_count: int = RunCount, condition: str = Condition) -> ReadResult:\n",
    "  ratios = []\n",
    "  notifications = []\n",
    "\n",
    "  no_activity_count = 0\n",
    "  for epoch in range(epoch_count):\n",
    "    frame = pd.read_csv(f\"{ResultsDirectory}/patient1_{condition}_{name}_run{epoch}.csv\")\n",
    "    has_performed_activity = any(frame['activity performed'].values)\n",
    "\n",
    "    if has_performed_activity:\n",
    "      ratios.append(frame.response_ratio)\n",
    "      notifications.append(frame.notifications)\n",
    "    else:\n",
    "      no_activity_count += 1\n",
    "\n",
    "  print(f\" {no_activity_count} out of {epoch_count} runs had no activity performed throughout the full intervention.\")\n",
    "  return ReadResult(ratios, notifications)\n",
    "\n",
    "def plot_experiment_results_ratio(label: str, not_random_result: ReadResult, result_map: Dict[str, ReadResult]):\n",
    "  figure: plt.Figure\n",
    "  figure, (ratios_axis, notifications_axis) = plt.subplots(2, 1, sharex=True, sharey=False, figsize=(10, 10))\n",
    "  figure.suptitle(f'profile \"{label}\": Comparison of prompt learning strategies', fontsize=20)\n",
    "  figure.subplots_adjust(top=0.9)\n",
    "\n",
    "  for label, (ratios, notifications) in result_map.items():\n",
    "    ratios_axis.plot(np.nanmean(ratios, axis=0), label=label)\n",
    "    notifications_axis.plot(np.nanmean(notifications, axis=0), label=label)\n",
    "\n",
    "  notifications_axis.plot(\n",
    "    np.ones(len(np.mean(not_random_result.notifications, axis=0)) + 2),\n",
    "    label='Preferred number of notifications a day'\n",
    "  )\n",
    "  notifications_axis.set_xlabel('Intervention Days', fontsize=16)\n",
    "  notifications_axis.set_ylabel('\\n'.join(wrap('Numbers of notifications', 20)), fontsize=16)\n",
    "  ratios_axis.set_ylabel('\\n'.join(wrap('Activity performed to prompt ratio', 20)))\n",
    "  notifications_axis.legend(fontsize=13)\n",
    "  plt.xticks(fontsize=14)\n",
    "  plt.yticks(fontsize=14)\n",
    "  plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93e58874eb6b0eea",
   "metadata": {},
   "source": [
    "## Experiment methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55854eef3fd8f320",
   "metadata": {},
   "source": [
    "### No intervention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6e52045acda151f9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-27T17:37:23.999354Z",
     "start_time": "2024-05-27T17:37:23.994028Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "from typing import Type\n",
    "\n",
    "def run_no_intervention_experiment(Profile: Type[Patient], epoch_count: int = RunCount) -> ExperimentResult:\n",
    "  sleep_hours = []\n",
    "  positive_hours = []\n",
    "  ratios = []\n",
    "  notifications = []\n",
    "\n",
    "  for _ in range(epoch_count):\n",
    "    environment = Profile(\n",
    "      behaviour_threshold=20,\n",
    "      habituation=Habituation,\n",
    "      time_preference_update_step=TimePreferenceUpdateStep\n",
    "    )\n",
    "\n",
    "    for _ in range(EightWeeksHours):\n",
    "      observation, reward, done, _, info = environment.step(0)\n",
    "\n",
    "    sleep_hours.append(environment.h_slept)\n",
    "    positive_hours.append(environment.h_positive)\n",
    "    ratios.append(environment.rr)\n",
    "    notifications.append(environment.num_notified)\n",
    "\n",
    "  return ExperimentResult(sleep_hours, positive_hours, ratios, notifications)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c9fb6db67b960",
   "metadata": {},
   "source": [
    "### Intervention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a2960a927cf00074",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-27T17:37:24.037282Z",
     "start_time": "2024-05-27T17:37:24.030495Z"
    }
   },
   "outputs": [],
   "source": [
    "from typing import Callable\n",
    "\n",
    "def save_epoch_to_csv(environment: Patient, condition: str, name: str, epoch: int):\n",
    "  df = pd.DataFrame()\n",
    "  df['response_ratio'] = environment.rr\n",
    "  df['activity performed'] = environment.num_performed\n",
    "  df['notifications'] = environment.num_notified\n",
    "  df['sleep'] = environment.h_slept\n",
    "  df['positive'] = environment.h_positive\n",
    "  df['non_stationary'] = environment.h_nonstationary\n",
    "  df.to_csv(f\"{ResultsDirectory}/patient1_{condition}_{name}_run{epoch}.csv\")\n",
    "\n",
    "Method = Callable[[Patient], Patient]\n",
    "def run_intervention_experiment(Patient: Type[Patient], method: Method, name: str, epoch_count=RunCount, condition=Condition):\n",
    "  ratios = []\n",
    "  notifications = []\n",
    "\n",
    "  sleep_hours = []\n",
    "  positive_mood_hours = []\n",
    "  times_performed = 0\n",
    "\n",
    "  for epoch in range(epoch_count):\n",
    "    environment = method(\n",
    "      Patient(\n",
    "        behaviour_threshold=20,\n",
    "        habituation=Habituation,\n",
    "        time_preference_update_step=TimePreferenceUpdateStep\n",
    "      )\n",
    "    )\n",
    "\n",
    "    if any(environment.num_performed): times_performed += 1\n",
    "\n",
    "    save_epoch_to_csv(environment, condition, name, epoch)\n",
    "\n",
    "    ratios.append(environment.rr)\n",
    "    notifications.append(environment.num_notified)\n",
    "    sleep_hours.append(environment.h_slept)\n",
    "    positive_mood_hours.append(environment.h_positive)\n",
    "\n",
    "  print(\"These figures include runs in which no prompt resulted in the activity being performed.\")\n",
    "  print(f\"{times_performed} out of {epoch_count} resulted in activity being performed.\")\n",
    "\n",
    "  return ExperimentResult(sleep_hours, positive_mood_hours, ratios, notifications)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b37d6ec095926907",
   "metadata": {},
   "source": [
    "### Heuristic\n",
    "\n",
    "Notify every hour except in night and when the patient is alseep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9e2bb316d4031f21",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-27T17:37:24.056230Z",
     "start_time": "2024-05-27T17:37:24.051856Z"
    }
   },
   "outputs": [],
   "source": [
    "def always_notify(environment: Patient, intervention_length: int = EightWeeksHours) -> Patient:\n",
    "  action = 0\n",
    "\n",
    "  for _ in range(intervention_length):\n",
    "    observation, _, _, _, _ = environment.step(action)\n",
    "    # 9-th is the time of the day\n",
    "    # 3 is the night\n",
    "    if observation[9] == 3 or observation[3] == 1:\n",
    "      action = 0\n",
    "    else:\n",
    "      action = 1\n",
    "\n",
    "  return environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8279c050cc16c27b",
   "metadata": {},
   "source": [
    "### Random \n",
    "Randomly sample during the day skip the nights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "af7364ff4f55808f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-27T17:37:24.076126Z",
     "start_time": "2024-05-27T17:37:24.072026Z"
    }
   },
   "outputs": [],
   "source": [
    "def random_notification(environment: Patient, intervention_length: int = EightWeeksHours) -> Patient:\n",
    "  action = 0\n",
    "  for i in range(intervention_length):\n",
    "\n",
    "    observation, _, _, _, _ = environment.step(action)\n",
    "    # 9-th is the time of the day\n",
    "    if observation[9] == 3:\n",
    "      action = 0\n",
    "    else:\n",
    "      action = environment.action_space.sample()\n",
    "\n",
    "  return environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c622eb0d9c2c44c4",
   "metadata": {},
   "source": [
    "### Supervised Learning\n",
    "\n",
    "#### Static model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "94775e3fa498f29b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-27T17:37:24.103995Z",
     "start_time": "2024-05-27T17:37:24.099888Z"
    }
   },
   "outputs": [],
   "source": [
    "def supervised_after_three_weeks(environment: Patient) -> Patient:\n",
    "  environment = always_notify(environment, intervention_length=ThreeWeeksHours)\n",
    "  classifier = RandomForestClassifier(class_weight='balanced')\n",
    "  classifier.fit(environment.observation_list, environment.activity_performed)\n",
    "\n",
    "  remaining_time = EightWeeksHours - ThreeWeeksHours\n",
    "  observation = environment._get_current_state()\n",
    "\n",
    "  for _ in range(remaining_time):\n",
    "    # applying supervised model\n",
    "    action = classifier.predict(np.array([observation]))[0]\n",
    "    observation, _, _, _, _ = environment.step(action)\n",
    "\n",
    "  return environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb2afa0e2c0247e7",
   "metadata": {},
   "source": [
    "### Adaptive model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "84b51376038dc63b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-27T17:37:24.141582Z",
     "start_time": "2024-05-27T17:37:24.137271Z"
    }
   },
   "outputs": [],
   "source": [
    "def supervised_adaptive_after_three_weeks(environment: Patient) -> Patient:\n",
    "  environment = always_notify(environment, intervention_length=ThreeWeeksHours)\n",
    "  classifier = RandomForestClassifier(class_weight='balanced')\n",
    "  classifier.fit(environment.observation_list, environment.activity_performed)\n",
    "\n",
    "  remaining_time = EightWeeksHours - ThreeWeeksHours\n",
    "  observation = environment._get_current_state()\n",
    "  samples = len(environment.observation_list)\n",
    "\n",
    "  for _ in range(remaining_time):\n",
    "    # applying supervised model\n",
    "    action = classifier.predict(np.array([observation]))[0]\n",
    "    observation, _, _, _, _ = environment.step(action)\n",
    "\n",
    "    if len(environment.observation_list) <= samples: continue\n",
    "    # retrain when new samples are provided\n",
    "    classifier = RandomForestClassifier(class_weight='balanced')\n",
    "    classifier.fit(environment.observation_list, environment.activity_performed)\n",
    "    samples = len(environment.observation_list)\n",
    "\n",
    "  return environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "953cf5644e94b717",
   "metadata": {},
   "source": [
    "### Deep Q Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "59923474b15608d2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-27T17:37:24.160009Z",
     "start_time": "2024-05-27T17:37:24.156983Z"
    }
   },
   "outputs": [],
   "source": [
    "def dqn(environment: Patient) -> Patient:\n",
    "  model = DQN(\"MlpPolicy\", environment, verbose=0, learning_starts=UpdatedEveryDayHours)\n",
    "  model.learn(total_timesteps=EightWeeksHours)\n",
    "  return environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29706f49651533e3",
   "metadata": {},
   "source": [
    "### Proximal Policy Optimisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1868248c15136180",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-27T17:37:24.165868Z",
     "start_time": "2024-05-27T17:37:24.161482Z"
    }
   },
   "outputs": [],
   "source": [
    "def ppo(environment: Patient) -> Patient:\n",
    "  model = PPO(\"MlpPolicy\", environment, verbose=0, n_steps=UpdatedEveryDayHours, batch_size=UpdatedEveryDayHours)\n",
    "  model.learn(total_timesteps=EightWeeksHours)\n",
    "  return environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cf33ea4cb093129",
   "metadata": {},
   "source": [
    "### Advantage Actor Critic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e95ecdb2e34f7db8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-27T17:37:24.204505Z",
     "start_time": "2024-05-27T17:37:24.198911Z"
    }
   },
   "outputs": [],
   "source": [
    "def a2c(environment: Patient) -> Patient:\n",
    "  model = A2C(\"MlpPolicy\", environment, verbose=0, n_steps=UpdatedEveryDayHours)\n",
    "  model.learn(total_timesteps=EightWeeksHours)\n",
    "  return environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bab71e6e0ff5c1d7",
   "metadata": {},
   "source": [
    "### Comparison between prompt learning strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "276c27d9f4f0ec59",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-05-27T17:37:24.223621Z"
    },
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running experiment for profile: 'Indifferent'\n",
      "\tRunning experiments...\n",
      "\t - no intervention\n",
      "\t - heuristic\n",
      "These figures include runs in which no prompt resulted in the activity being performed.\n",
      "38 out of 50 resulted in activity being performed.\n",
      "\t - random\n",
      "These figures include runs in which no prompt resulted in the activity being performed.\n",
      "42 out of 50 resulted in activity being performed.\n",
      "\t - supervised learning\n"
     ]
    }
   ],
   "source": [
    "def run_experiment_for_profile(Profile: Type[Patient], label: str):\n",
    "  print(\"\\tRunning experiments...\")\n",
    "  print(\"\\t - no intervention\")\n",
    "  result = run_no_intervention_experiment(Profile)\n",
    "  print(\"\\t - heuristic\")\n",
    "  run_intervention_experiment(Profile, always_notify, f'h-{label}')\n",
    "  print(\"\\t - random\")\n",
    "  run_intervention_experiment(Profile, random_notification, f'random-{label}')\n",
    "  print(\"\\t - supervised learning\")\n",
    "  run_intervention_experiment(Profile, supervised_after_three_weeks, f'static_sup3-{label}')\n",
    "  print(\"\\t - adaptive supervised learning\")\n",
    "  run_intervention_experiment(Profile, supervised_adaptive_after_three_weeks, f'adaptive_sup3-{label}')\n",
    "  print(\"\\t - dqn\")\n",
    "  run_intervention_experiment(Profile, dqn, f'dqn-{label}')\n",
    "  print(\"\\t - ppo\")\n",
    "  run_intervention_experiment(Profile, ppo, f'ppo-{label}')\n",
    "  print(\"\\t - a2c\")\n",
    "  run_intervention_experiment(Profile, a2c, f'a2c-{label}')\n",
    "  print(\"\\tDone.\")\n",
    "\n",
    "  always_notify_result = read_ratios_and_notifications(f'h-{label}')\n",
    "  random_result = read_ratios_and_notifications(f'random-{label}')\n",
    "  static_sup3_result = read_ratios_and_notifications(f'static_sup3-{label}')\n",
    "  adaptive_sup3_result = read_ratios_and_notifications(f'adaptive_sup3-{label}')\n",
    "  dqn_result = read_ratios_and_notifications(f'dqn-{label}')\n",
    "  ppo_result = read_ratios_and_notifications(f'ppo-{label}')\n",
    "  a2c_result = read_ratios_and_notifications(f'a2c-{label}')\n",
    "\n",
    "  plot_experiment_result_hours(result)\n",
    "  plot_experiment_results_ratio(label, random_result, {\n",
    "    'Heuristic': always_notify_result,\n",
    "    'Random': random_result,\n",
    "    'RF Static': static_sup3_result,\n",
    "    'RF Adaptive': adaptive_sup3_result,\n",
    "    'DQN': dqn_result,\n",
    "    'PPO': ppo_result,\n",
    "    'A2C': a2c_result\n",
    "  })\n",
    "\n",
    "for (label, Profile) in profiles.items():\n",
    "  print(f\"Running experiment for profile: '{label}'\")\n",
    "  run_experiment_for_profile(Profile, label)\n",
    "  print()\n",
    "  "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2d75e59403798c4677170d00bbf4f5c6471b09e4dee8847e501b2bf55ae87098"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
