{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Simulated Patient ",
   "id": "9ad6c90baa0dc1a1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from textwrap import wrap\n",
    "from matplotlib import pyplot as plt\n",
    "from stable_baselines3 import PPO, A2C, DQN\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ],
   "id": "259817bb4f94a937",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "from environment.profiles import profiles\n",
   "id": "a3e4b075d8be6bca",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "from environment.fogg_behavioural_model import Patient",
   "id": "6e5738d7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "UpdatedEveryDayHours = 24\n",
    "WeekHours = 7 * UpdatedEveryDayHours\n",
    "ThreeWeeksHours = WeekHours * 3\n",
    "EightWeeksHours = WeekHours * 8\n",
    "FiveWeeksHours = WeekHours * 5\n",
    "\n",
    "Condition = 'stable'\n",
    "Habituation = False\n",
    "#very high e.g. 9999999999 to make it outside of the intervention time...effectively no preference shift\n",
    "TimePreferenceUpdateStep = 9999999999999999\n",
    "# 500 runs in the paper\n",
    "RunCount = 50"
   ],
   "id": "b401c3c64ab3ecf3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "ResultsDirectory = 'results'\n",
    "if not os.path.exists(ResultsDirectory):\n",
    "  os.makedirs(ResultsDirectory)"
   ],
   "id": "fb010225b43237b0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Plots",
   "id": "3491eabb5a069453"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from typing import NamedTuple\n",
    "\n",
    "class ExperimentResult(NamedTuple):\n",
    "  sleep_hours: list[float]\n",
    "  positive_mood_hours: list[float]\n",
    "  response_ratios: list[float]\n",
    "  notifications: list[float]\n"
   ],
   "id": "126410b62f42eedd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def plot_experiment_result_hours(result: ExperimentResult):\n",
    "  (sleeps_hours, positive_moods_hours, _, _) = result\n",
    "\n",
    "  plt.figure(figsize=(8, 5))\n",
    "  plt.plot(np.nanmean(sleeps_hours, axis=0), label='Hours slept', color='r')\n",
    "  plt.plot(np.mean(positive_moods_hours, axis=0), label='Hours in positive mood')\n",
    "  plt.ylabel('Hours ')\n",
    "  plt.xlabel('Intervention Days')\n",
    "  plt.legend()\n",
    "  plt.show()\n",
    "\n",
    "def plot_experiment_result_ratios(result: ExperimentResult):\n",
    "  (_, _, ratios, notifications) = result\n",
    "\n",
    "  _, (ratios_axis, notifications_axis) = plt.subplots(2, 1, sharex=True, sharey=False, figsize=(10, 8))\n",
    "  ratios_axis.plot(np.nanmean(ratios, axis=0), label='response ratio', color='r')\n",
    "  notifications_axis.plot(np.nanmean(notifications, axis=0), label='num of notifications')\n",
    "  notifications_axis.set_xlabel('Intervention days')\n",
    "  notifications_axis.set_ylabel('No. of notifications')\n",
    "  ratios_axis.set_ylabel('Response ratio')\n",
    "  plt.show()\n",
    "\n",
    "class ReadResult(NamedTuple):\n",
    "  ratios: list[float]\n",
    "  notifications: list[float]\n",
    "\n",
    "def read_ratios_and_notifications(name: str, epoch_count: int = RunCount, condition: str = Condition) -> ReadResult:\n",
    "  ratios = []\n",
    "  notifications = []\n",
    "\n",
    "  no_activity_count = 0\n",
    "  for epoch in range(epoch_count):\n",
    "    frame = pd.read_csv(f\"{ResultsDirectory}/patient1_{condition}_{name}_run{epoch}.csv\")\n",
    "    has_performed_activity = any(frame['activity performed'].values)\n",
    "\n",
    "    if has_performed_activity:\n",
    "      ratios.append(frame.response_ratio)\n",
    "      notifications.append(frame.notifications)\n",
    "    else:\n",
    "      no_activity_count += 1\n",
    "\n",
    "  print(f\" {no_activity_count} out of {epoch_count} runs had no activity performed throughout the full intervention.\")\n",
    "  return ReadResult(ratios, notifications)\n",
    "\n",
    "def plot_experiment_results_ratio(label: str, not_random_result: ReadResult, result_map: dict[str, ReadResult]):\n",
    "  figure: plt.Figure\n",
    "  figure, (ratios_axis, notifications_axis) = plt.subplots(2, 1, sharex=True, sharey=False, figsize=(10, 10))\n",
    "  figure.suptitle(f'profile \"{label}\": Comparison of prompt learning strategies', fontsize=20)\n",
    "  figure.subplots_adjust(top=0.9)\n",
    "\n",
    "  for label, (ratios, notifications) in result_map.items():\n",
    "    ratios_axis.plot(np.nanmean(ratios, axis=0), label=label)\n",
    "    notifications_axis.plot(np.nanmean(notifications, axis=0), label=label)\n",
    "\n",
    "  notifications_axis.plot(\n",
    "    np.ones(len(np.mean(not_random_result.notifications, axis=0))) + 2,\n",
    "    label='Preferred number of notifications a day'\n",
    "  )\n",
    "  notifications_axis.set_xlabel('Intervention Days', fontsize=16)\n",
    "  notifications_axis.set_ylabel('\\n'.join(wrap('Numbers of notifications', 20)), fontsize=16)\n",
    "  ratios_axis.set_ylabel('\\n'.join(wrap('Activity performed to prompt ratio', 20)))\n",
    "  notifications_axis.legend(fontsize=13)\n",
    "  plt.xticks(fontsize=14)\n",
    "  plt.yticks(fontsize=14)\n",
    "  plt.show()\n"
   ],
   "id": "b18fc49b4d9ca3df",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Experiment methods",
   "id": "93e58874eb6b0eea"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### No intervention",
   "id": "55854eef3fd8f320"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "def run_no_intervention_experiment(Profile: type[Patient], epoch_count: int = RunCount) -> ExperimentResult:\n",
    "  sleep_hours = []\n",
    "  positive_hours = []\n",
    "  ratios = []\n",
    "  notifications = []\n",
    "\n",
    "  for _ in range(epoch_count):\n",
    "    environment = Profile(\n",
    "      behaviour_threshold=20,\n",
    "      habituation=Habituation,\n",
    "      time_preference_update_step=TimePreferenceUpdateStep\n",
    "    )\n",
    "\n",
    "    for _ in range(EightWeeksHours):\n",
    "      observation, reward, done, _, info = environment.step(0)\n",
    "\n",
    "    sleep_hours.append(environment.h_slept)\n",
    "    positive_hours.append(environment.h_positive)\n",
    "    ratios.append(environment.rr)\n",
    "    notifications.append(environment.num_notified)\n",
    "\n",
    "  return ExperimentResult(sleep_hours, positive_hours, ratios, notifications)\n"
   ],
   "id": "6e52045acda151f9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Intervention",
   "id": "61c9fb6db67b960"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from typing import Callable\n",
    "\n",
    "def save_epoch_to_csv(environment: Patient, condition: str, name: str, epoch: int):\n",
    "  df = pd.DataFrame()\n",
    "  df['response_ratio'] = environment.rr\n",
    "  df['activity performed'] = environment.num_performed\n",
    "  df['notifications'] = environment.num_notified\n",
    "  df['sleep'] = environment.h_slept\n",
    "  df['positive'] = environment.h_positive\n",
    "  df['non_stationary'] = environment.h_nonstationary\n",
    "  df.to_csv(f\"{ResultsDirectory}/patient1_{condition}_{name}_run{epoch}.csv\")\n",
    "\n",
    "Method = Callable[[Patient], Patient]\n",
    "def run_intervention_experiment(Patient: type[Patient], method: Method, name: str, epoch_count=RunCount, condition=Condition):\n",
    "  ratios = []\n",
    "  notifications = []\n",
    "\n",
    "  sleep_hours = []\n",
    "  positive_mood_hours = []\n",
    "  times_performed = 0\n",
    "\n",
    "  for epoch in range(epoch_count):\n",
    "    environment = method(\n",
    "      Patient(\n",
    "        behaviour_threshold=20,\n",
    "        habituation=Habituation,\n",
    "        time_preference_update_step=TimePreferenceUpdateStep\n",
    "      )\n",
    "    )\n",
    "\n",
    "    if any(environment.num_performed): times_performed += 1\n",
    "\n",
    "    save_epoch_to_csv(environment, condition, name, epoch)\n",
    "\n",
    "    ratios.append(environment.rr)\n",
    "    notifications.append(environment.num_notified)\n",
    "    sleep_hours.append(environment.h_slept)\n",
    "    positive_mood_hours.append(environment.h_positive)\n",
    "\n",
    "  print(\"These figures include runs in which no prompt resulted in the activity being performed.\")\n",
    "  print(f\"{times_performed} out of {epoch_count} resulted in activity being performed.\")\n",
    "\n",
    "  return ExperimentResult(sleep_hours, positive_mood_hours, ratios, notifications)\n"
   ],
   "id": "a2960a927cf00074",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Heuristic\n",
    "\n",
    "Notify every hour except in night and when the patient is alseep"
   ],
   "id": "b37d6ec095926907"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def always_notify(environment: Patient, intervention_length: int = EightWeeksHours) -> Patient:\n",
    "  action = 0\n",
    "\n",
    "  for _ in range(intervention_length):\n",
    "    observation, _, _, _, _ = environment.step(action)\n",
    "    # 9-th is the time of the day\n",
    "    # 3 is the night\n",
    "    if observation[9] == 3 or observation[3] == 1:\n",
    "      action = 0\n",
    "    else:\n",
    "      action = 1\n",
    "\n",
    "  return environment"
   ],
   "id": "9e2bb316d4031f21",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Random \n",
    "Randomly sample during the day skip the nights"
   ],
   "id": "8279c050cc16c27b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def random_notification(environment: Patient, intervention_length: int = EightWeeksHours) -> Patient:\n",
    "  action = 0\n",
    "  for i in range(intervention_length):\n",
    "\n",
    "    observation, _, _, _, _ = environment.step(action)\n",
    "    # 9-th is the time of the day\n",
    "    if observation[9] == 3:\n",
    "      action = 0\n",
    "    else:\n",
    "      action = environment.action_space.sample()\n",
    "\n",
    "  return environment"
   ],
   "id": "af7364ff4f55808f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Supervised Learning\n",
    "\n",
    "#### Static model"
   ],
   "id": "c622eb0d9c2c44c4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def supervised_after_three_weeks(environment: Patient) -> Patient:\n",
    "  environment = always_notify(environment, intervention_length=ThreeWeeksHours)\n",
    "  classifier = RandomForestClassifier(class_weight='balanced')\n",
    "  classifier.fit(environment.observation_list, environment.activity_performed)\n",
    "\n",
    "  remaining_time = EightWeeksHours - ThreeWeeksHours\n",
    "  observation = environment._get_current_state()\n",
    "\n",
    "  for _ in range(remaining_time):\n",
    "    # applying supervised model\n",
    "    action = classifier.predict(np.array([observation]))[0]\n",
    "    observation, _, _, _, _ = environment.step(action)\n",
    "\n",
    "  return environment"
   ],
   "id": "94775e3fa498f29b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Adaptive model ",
   "id": "cb2afa0e2c0247e7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def supervised_adaptive_after_three_weeks(environment: Patient) -> Patient:\n",
    "  environment = always_notify(environment, intervention_length=ThreeWeeksHours)\n",
    "  classifier = RandomForestClassifier(class_weight='balanced')\n",
    "  classifier.fit(environment.observation_list, environment.activity_performed)\n",
    "\n",
    "  remaining_time = EightWeeksHours - ThreeWeeksHours\n",
    "  observation = environment._get_current_state()\n",
    "  samples = len(environment.observation_list)\n",
    "\n",
    "  for _ in range(remaining_time):\n",
    "    # applying supervised model\n",
    "    action = classifier.predict(np.array([observation]))[0]\n",
    "    observation, _, _, _, _ = environment.step(action)\n",
    "\n",
    "    if len(environment.observation_list) <= samples: continue\n",
    "    # retrain when new samples are provided\n",
    "    classifier = RandomForestClassifier(class_weight='balanced')\n",
    "    classifier.fit(environment.observation_list, environment.activity_performed)\n",
    "    samples = len(environment.observation_list)\n",
    "\n",
    "  return environment"
   ],
   "id": "84b51376038dc63b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Deep Q Network",
   "id": "953cf5644e94b717"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def dqn(environment: Patient) -> Patient:\n",
    "  model = DQN(\"MlpPolicy\", environment, verbose=0, learning_starts=UpdatedEveryDayHours)\n",
    "  model.learn(total_timesteps=EightWeeksHours)\n",
    "  return environment"
   ],
   "id": "59923474b15608d2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Proximal Policy Optimisation",
   "id": "29706f49651533e3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def ppo(environment: Patient) -> Patient:\n",
    "  model = PPO(\"MlpPolicy\", environment, verbose=0, n_steps=UpdatedEveryDayHours, batch_size=UpdatedEveryDayHours)\n",
    "  model.learn(total_timesteps=EightWeeksHours)\n",
    "  return environment"
   ],
   "id": "1868248c15136180",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Advantage Actor Critic",
   "id": "5cf33ea4cb093129"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def a2c(environment: Patient) -> Patient:\n",
    "  model = A2C(\"MlpPolicy\", environment, verbose=0, n_steps=UpdatedEveryDayHours)\n",
    "  model.learn(total_timesteps=EightWeeksHours)\n",
    "  return environment"
   ],
   "id": "e95ecdb2e34f7db8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Comparison between prompt learning strategies",
   "id": "bab71e6e0ff5c1d7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def run_experiment_for_profile(Profile: type[Patient], label: str):\n",
    "  result = run_no_intervention_experiment(Profile)\n",
    "  run_intervention_experiment(Profile, always_notify, f'h-{label}')\n",
    "  run_intervention_experiment(Profile, random_notification, f'random-{label}')\n",
    "  run_intervention_experiment(Profile, supervised_adaptive_after_three_weeks, f'static_sup3-{label}')\n",
    "  run_intervention_experiment(Profile, supervised_adaptive_after_three_weeks, f'adaptive_sup3-{label}')\n",
    "  run_intervention_experiment(Profile, dqn, f'dqn-{label}')\n",
    "  run_intervention_experiment(Profile, ppo, f'ppo-{label}')\n",
    "  run_intervention_experiment(Profile, a2c, f'a2c-{label}')\n",
    "\n",
    "  always_notify_result = read_ratios_and_notifications(f'h-{label}')\n",
    "  random_result = read_ratios_and_notifications(f'random-{label}')\n",
    "  static_sup3_result = read_ratios_and_notifications(f'static_sup3-{label}')\n",
    "  adaptive_sup3_result = read_ratios_and_notifications(f'adaptive_sup3-{label}')\n",
    "  dqn_result = read_ratios_and_notifications(f'dqn-{label}')\n",
    "  ppo_result = read_ratios_and_notifications(f'ppo-{label}')\n",
    "  a2c_result = read_ratios_and_notifications(f'a2c-{label}')\n",
    "\n",
    "  plot_experiment_result_hours(result)\n",
    "  plot_experiment_results_ratio(random_result, {\n",
    "    'Heuristic': always_notify_result,\n",
    "    'Random': random_result,\n",
    "    'RF Static': static_sup3_result,\n",
    "    'RF Adaptive': adaptive_sup3_result,\n",
    "    'DQN': dqn_result,\n",
    "    'PPO': ppo_result,\n",
    "    'A2C': a2c_result\n",
    "  })\n",
    "\n",
    "for (label, Profile) in profiles.items():\n",
    "  print(f\"Running experiment for profile: '{label}'\")\n",
    "  run_experiment_for_profile(Profile, label)\n",
    "  print()\n",
    "  "
   ],
   "id": "276c27d9f4f0ec59"
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2d75e59403798c4677170d00bbf4f5c6471b09e4dee8847e501b2bf55ae87098"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "name": "python3",
   "language": "python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
